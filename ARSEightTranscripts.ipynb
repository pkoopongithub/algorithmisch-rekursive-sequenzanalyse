{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Algorithmic Recursive Sequence Analysis 2.0\n\n## Grammar induction from further transcripts after extensive sequence analysis of a transcript\n\nThis document presents the method of algorithmically recursive sequence analysis. \nThe goal of this method is to extract grammatical structures from natural language sequences \nto extract and then induce a grammar based on it. We focus on them\nAnalysis of transcripts prepared through extensive sequence analysis \nto recognize the underlying rules and patterns in the data.\n\n### Background\n\nSequence analysis in natural language data is a widely used approach in the \nLanguage processing to identify recurring patterns, structures and dependencies between \nto identify different parts of a sequence. In this extended version (2.0) \nwe integrate grammatical induction as a way from the analyzed\nto derive a formal grammar from sequences.\n\n### Goal setting\n\nThe main objectives of this approach include:\n\n1. **Extension of sequence analysis**: The analysis is applied to a broader set of transcripts to test whether the discovered patterns can be generalized beyond a single transcript.\n   \n2. **Grammar induction**: The knowledge gained from the sequences is used to extract grammatical rules and develop formalized grammars.\n\n3. **Quality Evaluation**: The quality of the induced grammar is evaluated based on its ability to generate future sequences that match the patterns in the transcripts.\n\n### Methodology\n\nThe method consists of several steps that are carried out iteratively:\n\n1. **Data preparation**: Collection and preprocessing of transcripts.\n   \n2. **Sequence analysis**: Carrying out an extensive sequence analysis with reading production and reading falsification on a transcript (loc. cit. in this repository). Conduct an extensive analysis of the transcripts, identifying statistical and syntactic patterns.\n\n3. **Grammar induction**: Based on the identified patterns, a formal grammar (Python here in the document) is induced that can describe the generated sequences.\n\n4. **Optimization**: The grammar is optimized (Python here in the document) and validated to increase its accuracy and generalizability.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "After evaluating specialist literature on sales discussions, the following preliminary hypothetical grammar emerges:\nA sales conversation (VKG) consists of a greeting (BG), a sales part (VT) and a farewell (AV).\n\n- The greeting consists of a greeting from the customer (KBG) and a greeting from the seller (VBG).\n- The farewell consists of a farewell by the customer (KAV) and a farewell by the seller (VAV).\n- The sales part consists of a requirements part (B) and a final part (A).\n  - The needs part includes a needs clarification (BBd) and a needs argument (BA).\n    - The needs clarification consists of the customer's needs (KBBd) and the associated clarifications from the seller (VBBd).\n    - The needs argument consists of arguments from the customer (KBA) and the seller (VBA).\n  - The closing part (A) consists of objections (AE) and a sales deal (AA).\n    - The objections consist of arguments from the customer (KAE) and the seller (VAE).\n    - The sales conclusion consists of arguments from the customer (KAA) and the seller (VAA).\n\nThe farewell (AV) consists of a farewell to the customer (KAV) and the seller (VAV).\n\nThe start symbol is therefore VKG, and the terminal characters for the categories are: KBG, VBG, KBBd, VBBd, KBA, VBA, KAE, VAE, KAA, VAA, KAV and VAV. From this information, create a probabilistic context-free grammar with initially assumed transition probabilities.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "First, a transcript was created from an intensive sequence analysis with readings production and \nReading falsification, category formation, intercoding correlation and grammar induction with schema \nand grammar transduction with Lisp and parsing the \nTerminal chain carried out with Object Pascal (loc. cit. in this repository).\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The procedure can be divided into several clearly defined steps. Here's an overview to make sure all steps are understandable:\n\n### 1. **Formation of hypotheses about grammar**\n   - Conduct a preliminary investigation to create a **hypothetical PCFG**. This serves as a guide, but is not binding for the analysis of the transcripts.\n\n### 2. **Analysis of the transcripts**\n   - Each **transcript is analyzed individually**. The intentions of the speakers and the structure of the interactions are identified.\n   - Each interaction in the transcript is assigned a **terminal character**. This results in a **terminal string** for each transcript.\n\n### 3. **Induction of a grammar for each transcript**\n   - A specific **grammar is induced** from the terminal string of each transcript.\n   - There is a separate **grammar per transcript** at the end (eight in total).\n\n### 4. **Unification of Grammars**\n   - The eight individual grammars are merged into a **unified grammar** that covers the structure of all transcripts.\n\n### 5. **Parsing terminal strings**\n   - The eight terminal strings of the transcripts are checked for **well-formedness** with respect to the unified grammar. This means that each string should be correctly recognized and parsed by the grammar.\n\n### 6. **Optimization of PCFG**\n   - A first version of a PCFG is created from the previous analyses.\n   - With the created PCFG, **artificial terminal strings** are created.\n   - The **proportional frequency of the terminal characters** from the artificial strings is compared with the frequency of the terminal characters in the real data (the eight transcripts).\n   - The **significance** of this correlation is measured.\n   - Adjustments to the PCFG are made until the correlation is satisfactory.\n\n### 7. **Repeat Process**\n   - Steps 6 and 7 are repeated until there is a good fit between the **empirical data** and the generated PCFG.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Here is a probabilistic context-free grammar (PCFG) based on structure. In a PCFG, probabilities for transitions between different production rules are defined. Since you just provided a structure without specific probabilities, I'll assume equal probabilities for the possible options within the same level to provide a baseline. These probabilities can be adjusted later when empirical data becomes available.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Probabilistische hypothetische kontextfreie Grammatik (PCFG) für ein Verkaufsgespräch\n\nVKG -> BG VT AV [1.0]\n\n# Begrüßung\nBG -> KBG VBG [1.0]\nKBG -> 'Kunden-Gruß'\nVBG -> 'Verkäufer-Gruß'\n\n# Verabschiedung\nAV -> KAV VAV [1.0]\nKAV -> 'Kunden-Verabschiedung'\nVAV -> 'Verkäufer-Verabschiedung'\n\n# Verkaufsteil\nVT -> B A [1.0]\n\n# Bedarfsteil\nB -> BBd BA [1.0]\n\n# Bedarfsklärung\nBBd -> KBBd VBBd [1.0]\nKBBd -> 'Kunden-Bedarf'\nVBBd -> 'Verkäufer-Klärung'\n\n# Bedarfsargumentation\nBA -> KBA VBA [0.5] | VBA KBA [0.5]\nKBA -> 'Kunden-Argument'\nVBA -> 'Verkäufer-Argument'\n\n# Abschlussteil\nA -> AE AA [1.0]\n\n# Einwände\nAE -> KAE VAE [0.5] | VAE KAE [0.5]\nKAE -> 'Kunden-Einwand'\nVAE -> 'Verkäufer-Einwand'\n\n# Verkaufsabschluss\nAA -> KAA VAA [0.5] | VAA KAA [0.5]\nKAA -> 'Kunden-Abschluss'\nVAA -> 'Verkäufer-Abschluss'\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The eight Transcripts (Audio file here in Repository).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "\n### **Text 1**\n**Datum:** 28. Juni 1994, **Ort:** Metzgerei, Aachen, 11:00 Uhr\n\n*(Die Geräusche eines geschäftigen Marktplatzes im Hintergrund, Stimmen und Gemurmel)*\n\n**Verkäuferin:** Guten Tag, was darf es sein?\n\n**Kunde:** Einmal von der groben Leberwurst, bitte.\n\n**Verkäuferin:** Wie viel darf’s denn sein?\n\n**Kunde:** Zwei hundert Gramm.\n\n**Verkäuferin:** Zwei hundert Gramm. Sonst noch etwas?\n\n**Kunde:** Ja, dann noch ein Stück von dem Schwarzwälder Schinken.\n\n**Verkäuferin:** Wie groß soll das Stück sein?\n\n**Kunde:** So um die dreihundert Gramm.\n\n**Verkäuferin:** Alles klar. Kommt sofort. *(Geräusche von Papier und Verpackung)*\n\n**Kunde:** Danke schön.\n\n**Verkäuferin:** Das macht dann acht Mark zwanzig.\n\n**Kunde:** Bitte. *(Klimpern von Münzen, Geräusche der Kasse)*\n\n**Verkäuferin:** Danke und einen schönen Tag noch!\n\n**Kunde:** Danke, ebenfalls!\n\n**Ende Text 1**\n\n---\n\n### **Text 2**\n**Datum:** 28. Juni 1994, **Ort:** Marktplatz, Aachen\n\n*(Ständige Hintergrundgeräusche von Stimmen und Marktatmosphäre)*\n\n**Verkäufer:** Kirschen kann jeder probieren hier, Kirschen kann jeder probieren hier!\n\n**Kunde 1:** Ein halbes Kilo Kirschen, bitte.\n\n**Verkäufer:** Ein halbes Kilo? Oder ein Kilo?\n\n*(Unverständliches Gespräch, Münzen klimpern)*\n\n**Verkäufer:** Danke schön!\n\n**Verkäufer:** Kirschen kann jeder probieren hier! Drei Mark, bitte.\n\n**Kunde 1:** Danke schön!\n\n**Verkäufer:** Kirschen kann jeder probieren hier, Kirschen kann jeder probieren hier!\n\n*(Weitere Stimmen im Hintergrund, unverständliches Gespräch, Münzen klimpern)*\n\n**Kunde 2:** Ein halbes Kilo, bitte.\n\n*(Unverständliches Gespräch)*\n\n**Ende Text 2**\n\n---\n\n### **Text 3**\n**Datum:** 28. Juni 1994, **Ort:** Fischstand, Marktplatz, Aachen\n\n*(Marktatmosphäre, Gespräch im Hintergrund, teilweise unverständlich)*\n\n**Kunde:** Ein Pfund Seelachs, bitte.\n\n**Verkäufer:** Seelachs, alles klar.\n\n*(Geräusche von Verpackung und Verkaufsvorbereitungen)*\n\n**Verkäufer:** Vier Mark neunzehn, bitte.\n\n*(Geräusche von Verpackung, Münzen klimpern)*\n\n**Verkäufer:** Schönen Dank!\n\n**Kunde:** Ja, danke schön!\n\n**Ende Text 3**\n\n---\n\n### **Text 4**\n**Datum:** 28. Juni 1994, **Ort:** Gemüsestand, Aachen, Marktplatz, 11:00 Uhr\n\n*(Marktatmosphäre, teilweise unverständlich)*\n\n**Kunde:** Hören Sie, ich nehme ein paar Champignons mit.\n\n**Verkäufer:** Braune oder helle?\n\n**Kunde:** Nehmen wir die hellen.\n\n**Verkäufer:** Alles klar, die hellen.\n\n*(Unverständliche Unterhaltung im Hintergrund)*\n\n**Verkäufer:** Die sind beide frisch, keine Sorge.\n\n**Kunde:** Wie ist es mit Pfifferlingen?\n\n**Verkäufer:** Ah, die sind super!\n\n*(Unverständliches Gespräch)*\n\n**Kunde:** Kann ich die in Reissalat tun?\n\n**Verkäufer:** Eher kurz anbraten in der Pfanne.\n\n**Kunde:** Okay, mache ich.\n\n**Verkäufer:** Die können Sie roh verwenden, aber ein bisschen anbraten ist besser.\n\n**Kunde:** Verstanden.\n\n*(Weitere Unterhaltung, unverständliche Kommentare)*\n\n**Verkäufer:** Noch etwas anderes?\n\n**Kunde:** Ja, dann nehme ich noch Erdbeeren.\n\n*(Pause, Hintergrundgeräusche von Verpackung und Stimmen)*\n\n**Verkäufer:** Schönen Tag noch!\n\n**Kunde:** Gleichfalls!\n\n**Ende Text 4**\n\n---\n\n### **Text 5**\n**Datum:** 26. Juni 1994, **Ort:** Gemüsestand, Aachen, Marktplatz, 11:00 Uhr\n\n*(Marktatmosphäre, teilweise unverständlich)*\n\n**Verkäufer:** So, bitte schön.\n\n**Kunde 1:** Auf Wiedersehen!\n\n**Kunde 2:** Ich hätte gern ein Kilo von den Granny Smith Äpfeln hier.\n\n*(Unverständliches Gespräch im Hintergrund)*\n\n**Verkäufer:** Sonst noch etwas?\n\n**Kunde 2:** Ja, noch ein Kilo Zwiebeln.\n\n**Verkäufer:** Alles klar.\n\n*(Unverständliches Gespräch, Hintergrundgeräusche)*\n\n**Kunde 2:** Das war's.\n\n**Verkäufer:** Sechs Mark fünfundzwanzig, bitte.\n\n*(Unverständliches Gespräch, Geräusche von Münzen und Verpackung)*\n\n**Verkäufer:** Wiedersehen!\n\n**Kunde 2:** Wiedersehen!\n\n**Ende Text 5**\n\n---\n\n### **Text 6**\n**Datum:** 28. Juni 1994, **Ort:** Käseverkaufsstand, Aachen, Marktplatz\n\n*(Marktatmosphäre, Begrüßungen)*\n\n**Kunde 1:** Guten Morgen!\n\n**Verkäufer:** Guten Morgen!\n\n**Kunde 1:** Ich hätte gerne fünfhundert Gramm holländischen Gouda.\n\n**Verkäufer:** Am Stück?\n\n**Kunde 1:** Ja, am Stück, bitte.\n\n**Ende Text 6**\n\n---\n\n### **Text 7**\n**Datum:** 28. Juni 1994, **Ort:** Bonbonstand, Aachen, Marktplatz, 11:30 Uhr\n\n*(Geräusche von Stimmen und Marktatmosphäre, teilweise unverständlich)*\n\n**Kunde:** Von den gemischten hätte ich gerne hundert Gramm.\n\n*(Unverständliche Fragen und Antworten)*\n\n**Verkäufer:** Für zu Hause oder zum Mitnehmen?\n\n**Kunde:** Zum Mitnehmen, bitte.\n\n**Verkäufer:** Fünfzig Pfennig, bitte.\n\n*(Klimpern von Münzen, Geräusche von Verpackung)*\n\n**Kunde:** Danke!\n\n**Ende Text 7**\n\n---\n\n### **Text 8**\n**Datum:** 9. Juli 1994, **Ort:** Bäckerei, Aachen, 12:00 Uhr\n\n*(Schritte hörbar, Hintergrundgeräusche, teilweise unverständlich)*\n\n**Kunde:** Guten Tag!\n\n*(Unverständliche Begrüßung im Hintergrund)*\n\n**Verkäuferin:** Einmal unser bester Kaffee, frisch gemahlen, bitte.\n\n*(Geräusche der Kaffeemühle, Verpackungsgeräusche)*\n\n**Verkäuferin:** Sonst noch etwas?\n\n**Kunde:** Ja, noch zwei Stück Obstsalat und ein Schälchen Sahne.\n\n**Verkäuferin:** In Ordnung!\n\n*(Geräusche der Kaffeemühle, Papiergeräusche)*\n\n**Verkäuferin:** Ein kleines Schälchen Sahne, ja?\n\n**Kunde:** Ja, danke.\n\n*(Türgeräusch, Lachen, Papiergeräusche)*\n\n**Verkäuferin:** Keiner kümmert sich darum, die Türen zu ölen.\n\n**Kunde:** Ja, das ist immer so.\n\n*(Lachen, Geräusche von Münzen und Verpackung)*\n\n**Verkäuferin:** Das macht vierzehn Mark und neunzehn Pfennig, bitte.\n\n**Kunde:** Ich zahle in Kleingeld.\n\n*(Lachen und Geräusche von Münzen)*\n\n**Verkäuferin:** Vielen Dank, schönen Sonntag noch!\n\n**Kunde:** Danke, Ihnen auch!\n\n**Ende Text 8**\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Auf Grundlage der vorläufigen probabilistischen kontextfreien Grammatik (PCFG) werden die Transkripte in die entsprechenden Terminalzeichen umwandeln. Hier ist die detaillierte Zuordnung für jedes Transkript, wobei für jede relevante Aktion oder Aussage des Gesprächs ein passendes Terminalzeichen aus der vorgegebenen Grammatik verwende.\n\n### **Transkript 1 - Terminalzeichen**\n**Datum:** 28. Juni 1994, **Ort:** Metzgerei, Aachen, 11:00 Uhr\n\n| Transkriptausschnitt                               | Terminalzeichen |\n|----------------------------------------------------|-----------------|\n| Kunde: Guten Tag                                   | `KBG` (Kunden-Gruß) \n| Verkäuferin: Guten Tag                             | `VBG` (Verkäufer-Gruß) \n| Kunde: Einmal von der groben Leberwurst, bitte.    | `KBBd` (Kunden-Bedarf) \n| Verkäuferin: Wie viel darf’s denn sein?            | `VBBd` (Verkäufer-Klärung) \n| Kunde: Zwei hundert Gramm.                         | `KBA` (Kunden-Argument) \n| Verkäuferin: Sonst noch etwas?                     | `VBA` (Verkäufer-Argument) \n| Kunde: Ja, dann noch ein Stück von dem Schwarzwälde| `KBBd` (Kunden-Bedarf) \n| Verkäuferin: Wie groß soll das Stück sein?         | `VBBd` (Verkäufer-Klärung) \n| Kunde: So um die dreihundert Gramm.                | `KBA` (Kunden-Argument) \n| Verkäuferin: Das macht dann acht Mark zwanzig.     | `VAA` (Verkäufer-Abschluss) \n| Kunde: Bitte.                                      | `KAA` (Kunden-Abschluss) \n| Verkäuferin: Danke und einen schönen Tag noch!     | `VAV` (Verkäufer-Verabschiedung) \n| Kunde: Danke, ebenfalls!                           | `KAV` (Kunden-Verabschiedung)|\n\n### **Transkript 2 - Terminalzeichen**\n**Datum:** 28. Juni 1994, **Ort:** Marktplatz, Aachen\n\n| Transkriptausschnitt                               | Terminalzeichen |\n|----------------------------------------------------|-----------------|\n| Verkäufer: Kirschen kann jeder probieren hier!     | `VBG` (Verkäufer-Gruß) \n| Kunde 1: Ein halbes Kilo Kirschen, bitte.          | `KBBd` (Kunden-Bedarf) \n| Verkäufer: Ein halbes Kilo? Oder ein Kilo?         | `VBBd` (Verkäufer-Klärung) \n| Verkäufer: Drei Mark, bitte.                       | `VAA` (Verkäufer-Abschluss) \n| Kunde 1: Danke schön!                              | `KAA` (Kunden-Abschluss) \n| Verkäufer: Kirschen kann jeder probieren hier!     | `VBG` (Verkäufer-Gruß) \n| Kunde 2: Ein halbes Kilo, bitte.                   | `KBBd` (Kunden-Bedarf) \n| Verkäufer: Drei Mark, bitte.                       | `VAA` (Verkäufer-Abschluss) \n| Kunde 2: Danke schön!                              | `KAA` (Kunden-Abschluss) \n\n### **Transkript 3 - Terminalzeichen**\n**Datum:** 28. Juni 1994, **Ort:** Fischstand, Marktplatz, Aachen\n\n| Transkriptausschnitt                               | Terminalzeichen |\n|----------------------------------------------------|-----------------|\n| Kunde: Ein Pfund Seelachs, bitte.                  | `KBBd` (Kunden-Bedarf) \n| Verkäufer: Seelachs, alles klar.                   | `VBBd` (Verkäufer-Klärung) \n| Verkäufer: Vier Mark neunzehn, bitte.              | `VAA` (Verkäufer-Abschluss) \n| Kunde: Danke schön!                                | `KAA` (Kunden-Abschluss) \n\n### **Transkript 4 - Terminalzeichen**\n**Datum:** 28. Juni 1994, **Ort:** Gemüsestand, Aachen, Marktplatz, 11:00 Uhr\n\n| Transkriptausschnitt                               | Terminalzeichen |\n|----------------------------------------------------|-----------------|\n| Kunde: Hören Sie, ich nehme ein paar Champignons mit. | `KBBd` (Kunden-Bedarf) \n| Verkäufer: Braune oder helle?                      | `VBBd` (Verkäufer-Klärung) \n| Kunde: Nehmen wir die hellen.                      | `KBA` (Kunden-Argument) \n| Verkäufer: Die sind beide frisch, keine Sorge.     | `VBA` (Verkäufer-Argument) \n| Kunde: Wie ist es mit Pfifferlingen?               | `KBBd` (Kunden-Bedarf) \n| Verkäufer: Ah, die sind super!                     | `VBA` (Verkäufer-Argument) \n| Kunde: Kann ich die in Reissalat tun?              | `KAE` (Kunden-Einwand) \n| Verkäufer: Eher kurz anbraten in der Pfanne.       | `VAE` (Verkäufer-Einwand) \n| Kunde: Okay, mache ich.                            | `KAA` (Kunden-Abschluss) \n| Verkäufer: Schönen Tag noch!                       | `VAV` (Verkäufer-Verabschiedung) \n| Kunde: Gleichfalls!                                | `KAV` (Kunden-Verabschiedung) \n\n### **Transkript 5 - Terminalzeichen**\n**Datum:** 26. Juni 1994, **Ort:** Gemüsestand, Aachen, Marktplatz, 11:00 Uhr\n\n| Transkriptausschnitt                               | Terminalzeichen |\n|----------------------------------------------------|-----------------|\n| Kunde 1: Auf Wiedersehen!                          | `KAV` (Kunden-Verabschiedung) \n| Kunde 2: Ich hätte gern ein Kilo von den Granny Smi| `KBBd` (Kunden-Bedarf) \n| Verkäufer: Sonst noch etwas?                       | `VBBd` (Verkäufer-Klärung) \n| Kunde 2: Ja, noch ein Kilo Zwiebeln.               | `KBBd` (Kunden-Bedarf)\n| Verkäufer: Sechs Mark fünfundzwanzig, bitte.       | `VAA` (Verkäufer-Abschluss) \n| Kunde 2: Auf Wiedersehen!                          | `KAV` (Kunden-Verabschiedung) \n\n### **Transkript 6 - Terminalzeichen**\n**Datum:** 28. Juni 1994, **Ort:** Käseverkaufsstand, Aachen, Marktplatz\n\n| Transkriptausschnitt                               | Terminalzeichen |\n|----------------------------------------------------|-----------------|\n| Kunde 1: Guten Morgen!                             | `KBG` (Kunden-Gruß) \n| Verkäufer: Guten Morgen!                           | `VBG` (Verkäufer-Gruß) \n| Kunde 1: Ich hätte gerne fünfhundert Gramm holländi| `KBBd` (Kunden-Bedarf) \n| Verkäufer: Am Stück?                               | `VBBd` (Verkäufer-Klärung) \n| Kunde 1: Ja, am Stück, bitte.                      | `KAA` (Kunden-Abschluss) \n\n### **Transkript 7 - Terminalzeichen**\n**Datum:** 28. Juni 1994, **Ort:** Bonbonstand, Aachen, Marktplatz, 11:30 Uhr\n\n| Transkriptausschnitt                               | Terminalzeichen |\n|----------------------------------------------------|-----------------|\n| Kunde: Von den gemischten hätte ich gerne hundert G| `KBBd` (Kunden-Bedarf) \n| Verkäufer: Für zu Hause oder zum Mitnehmen?        | `VBBd` (Verkäufer-Klärung) \n| Kunde: Zum Mitnehmen, bitte.                       | `KBA` (Kunden-Argument) \n| Verkäufer: Fünfzig Pfennig, bitte.                 | `VAA` (Verkäufer-Abschluss) \n| Kunde: Danke!                                      | `KAA` (Kunden-Abschluss) \n\n### **Transkript 8 - Terminalzeichen**\n**Datum:** 9. Juli 1994, **Ort:** Bäckerei, Aachen, 12:00 Uhr\n\n| Transkriptausschnitt                               | Terminalzeichen |\n|----------------------------------------------------|-----------------|\n| Kunde: Guten Tag!                                  | `KBG` (Kunden-Gruß) \n| Verkäuferin: Einmal unser bester Kaffee, frisch gem| `VBBd` (Verkäufer-Klärung) \n| Kunde: Ja, noch zwei Stück Obstsalat und ein Schälc| `KBBd` (Kunden-Bedarf) \n| Verkäuferin: In Ordnung!                           | `VBA` (Verkäufer-Argument) \n| Verkäuferin: Das macht vierzehn Mark und neunzehn P| `VAA` (Verkäufer-Abschluss) \n| Kunde: Ich zahle in Kleingeld.                     | `KAA` (Kunden-Abschluss) \n| Verkäuferin: Vielen Dank, schönen Sonntag noch!    | `VAV` (Verkäufer-Verabschiedung) \n| Kunde: Danke, Ihnen auch!                          | `KAV` (Kunden-Verabschiedung\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom scipy.stats import pearsonr\n\n# Neue empirische Terminalzeichenketten\nempirical_chains = [\n    ['KBG', 'VBG', 'KBBd', 'VBBd', 'KBA', 'VBA', 'KBBd', 'VBBd', 'KBA', 'VAA', 'KAA', 'VAV', 'KAV'],\n    ['VBG', 'KBBd', 'VBBd', 'VAA', 'KAA', 'VBG', 'KBBd', 'VAA', 'KAA'],\n    ['KBBd', 'VBBd', 'VAA', 'KAA'],\n    ['KBBd', 'VBBd', 'KBA', 'VBA', 'KBBd', 'VBA', 'KAE', 'VAE', 'KAA', 'VAV', 'KAV'],\n    ['KAV', 'KBBd', 'VBBd', 'KBBd', 'VAA', 'KAV'],\n    ['KBG', 'VBG', 'KBBd', 'VBBd', 'KAA'],\n    ['KBBd', 'VBBd', 'KBA', 'VAA', 'KAA'],\n    ['KBG', 'VBBd', 'KBBd', 'VBA', 'VAA', 'KAA', 'VAV', 'KAV']\n]\n\n# Übergangszählung initialisieren\ntransitions = {}\nfor chain in empirical_chains:\n    for i in range(len(chain) - 1):\n        start, end = chain[i], chain[i + 1]\n        if start not in transitions:\n            transitions[start] = {}\n        if end not in transitions[start]:\n            transitions[start][end] = 0\n        transitions[start][end] += 1\n\n# Normalisierung: Übergangswahrscheinlichkeiten berechnen\nprobabilities = {}\nfor start in transitions:\n    total = sum(transitions[start].values())\n    probabilities[start] = {end: count / total for end, count in transitions[start].items()}\n\n# Terminalzeichen und Startzeichen definieren\nterminal_symbols = list(set([item for sublist in empirical_chains for item in sublist]))\nstart_symbol = empirical_chains[0][0]\n\n# Funktion zur Generierung von Ketten basierend auf der Grammatik\ndef generate_chain(max_length=10):\n    chain = [start_symbol]\n    while len(chain) < max_length:\n        current = chain[-1]\n        if current not in probabilities:\n            break\n        next_symbol = np.random.choice(list(probabilities[current].keys()), p=list(probabilities[current].values()))\n        chain.append(next_symbol)\n        if next_symbol not in probabilities:\n            break\n    return chain\n\n# Funktion zur Berechnung relativer Häufigkeiten\ndef compute_frequencies(chains, terminals):\n    frequency_array = np.zeros(len(terminals))\n    terminal_index = {term: i for i, term in enumerate(terminals)}\n    \n    for chain in chains:\n        for symbol in chain:\n            if symbol in terminal_index:\n                frequency_array[terminal_index[symbol]] += 1\n\n    total = frequency_array.sum()\n    if total > 0:\n        frequency_array /= total  # Normierung der Häufigkeiten\n    \n    return frequency_array\n\n# Iterative Optimierung\nmax_iterations = 1000\ntolerance = 0.01  # Toleranz für Standardmessfehler\nbest_correlation = 0\nbest_significance = 1\n\n# Relativ Häufigkeiten der empirischen Ketten berechnen\nempirical_frequencies = compute_frequencies(empirical_chains, terminal_symbols)\n\nfor iteration in range(max_iterations):\n    # Generiere 8 künstliche Ketten\n    generated_chains = [generate_chain() for _ in range(8)]\n    \n    # Relativ Häufigkeiten der generierten Ketten berechnen\n    generated_frequencies = compute_frequencies(generated_chains, terminal_symbols)\n    \n    # Berechne die Korrelation\n    correlation, p_value = pearsonr(empirical_frequencies, generated_frequencies)\n    \n    print(f\"Iteration {iteration + 1}, Korrelation: {correlation:.3f}, Signifikanz: {p_value:.3f}\")\n    \n    # Überprüfen, ob Korrelation und Signifikanz akzeptabel sind\n    if correlation >= 0.9 and p_value < 0.05:\n        best_correlation = correlation\n        best_significance = p_value\n        break\n    \n    # Anpassung der Wahrscheinlichkeiten basierend auf Standardmessfehler\n    for start in probabilities:\n        for end in probabilities[start]:\n            # Fehlerabschätzung basierend auf Differenz der Häufigkeiten\n            empirical_prob = empirical_frequencies[terminal_symbols.index(end)]\n            generated_prob = generated_frequencies[terminal_symbols.index(end)]\n            error = empirical_prob - generated_prob\n            \n            # Anpassung der Wahrscheinlichkeit\n            probabilities[start][end] += error * tolerance\n            probabilities[start][end] = max(0, min(1, probabilities[start][end]))  # Begrenzen auf [0,1]\n    \n    # Normalisierung\n    for start in probabilities:\n        total = sum(probabilities[start].values())\n        if total > 0:\n            probabilities[start] = {end: prob / total for end, prob in probabilities[start].items()}\n\n# Ergebnis ausgeben\nprint(\"\\nOptimierte probabilistische Grammatik:\")\nfor start, transitions in probabilities.items():\n    print(f\"{start} → {transitions}\")\n\nprint(f\"\\nBeste Korrelation: {best_correlation:.3f}, Signifikanz: {best_significance:.3f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Iteration 1, Korrelation: 0.861, Signifikanz: 0.000\nIteration 2, Korrelation: 0.835, Signifikanz: 0.001\nIteration 3, Korrelation: 0.903, Signifikanz: 0.000\n\nOptimierte probabilistische Grammatik:\nKBG → {'VBG': 0.6665949194957433, 'VBBd': 0.33340508050425677}\nVBG → {'KBBd': 1.0}\nKBBd → {'VBBd': 0.6661627789328691, 'VAA': 0.16672317719273486, 'VBA': 0.16711404387439593}\nVBBd → {'KBA': 0.4444746815960467, 'VAA': 0.22218925521330254, 'KBBd': 0.2214541950661155, 'KAA': 0.11188186812453531}\nKBA → {'VBA': 0.5001954483997749, 'VAA': 0.4998045516002252}\nVBA → {'KBBd': 0.4995306939857028, 'KAE': 0.25025106688027127, 'VAA': 0.2502182391340259}\nVAA → {'KAA': 0.8573622459421577, 'KAV': 0.1426377540578423}\nKAA → {'VAV': 0.750137275176534, 'VBG': 0.24986272482346608}\nVAV → {'KAV': 1.0}\nKAE → {'VAE': 1.0}\nVAE → {'KAA': 1.0}\nKAV → {'KBBd': 1.0}\n\nBeste Korrelation: 0.903, Signifikanz: 0.000\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}