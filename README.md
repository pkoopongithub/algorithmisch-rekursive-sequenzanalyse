# Popper und die Grenzen großer Sprachmodelle (LLMs)

## Einleitung
Karl Popper betonte, dass die Menschheit das Leid der Evolution mindern kann, indem falsche Theorien durch kritisches Denken und explizite Erklärungen erkannt und verworfen werden. Auf diese Weise wird Fortschritt ermöglicht, ohne dass unnötiges menschliches Leid entsteht.

Große Sprachmodelle (LLMs) stellen in diesem Zusammenhang eine Herausforderung dar. Sie entwickeln keine expliziten Theorien und liefern keine Erklärungen, sondern operieren allein auf der Grundlage statistischer Muster. Diese Opazität erschwert eine kritische Überprüfung ihrer Ergebnisse und macht sie ungeeignet, um komplexe systemische Zusammenhänge oder soziale Missstände umfassend zu analysieren. Ähnlich einem Schauspieler, der einen Chirurgen nachahmt, simulieren LLMs Expertise, ohne die zugrunde liegenden Probleme erklären zu können – etwa soziale Ungleichheit oder Defizite im Gesundheitswesen.

Im Sinne von Poppers Philosophie sind jedoch explizite Erklärungen und Kritik unverzichtbar, um Fortschritt ohne Leid zu ermöglichen. LLMs, die diese Anforderungen nicht erfüllen, können daher nicht als geeignete Werkzeuge für eine kritische und aufgeklärte Gesellschaft betrachtet werden.

---

## Algorithmische Rekursive Sequenzanalyse (ARS 2.0)

### Projektbeschreibung
Dieses Projekt widmet sich der Entwicklung und Anwendung der Algorithmisch Rekursiven Sequenzanalyse (ARS 2.0), um die Dynamik von Gesprächen zu analysieren und zu modellieren. ARS 2.0 nutzt probabilistische kontextfreie Grammatiken (PCFG) und Multiagentensysteme (MAS), um Interaktionen zu simulieren und zu optimieren, insbesondere im Kontext von Verkaufsgesprächen.

### Ziele
1. **Modellierung von Gesprächen:** Analyse und Simulation typischer Gesprächsabläufe.
2. **KI-Optimierung:** Entwicklung von Multiagentensystemen basierend auf induzierten Grammatiken.
3. **Wissenschaftliche Grundlagen:** Bereitstellung methodischer Ansätze für soziale Interaktionen, Verhandlungen und Beratungen.

### Methoden
- **Grammatikinduktion:** Erstellung probabilistischer Grammatiken auf Basis von Transkripten.
- **Simulation mit Multiagentensystemen:** Modellierung von Interaktionen.
- **Optimierung durch Datenanalyse:** Anpassung der Grammatiken durch empirische Vergleiche.

---

## Fortschritte und Implementierungen 2024

### Transkripte und Analysen
- **Grammatikinduktion:**
  - [ARS20AchtTranskripte.ipynb](link)
  - [ars20achttranskripte.pdf](link)

- **Einzeltranskriptanalyse:**
  - [ARS20BeispielEng.pdf](link)
  - [ARS20BeispielGer.pdf](link)

### Optimierung der Grammatik
- **Übergangswahrscheinlichkeiten:**
  - [ARS20GramOpt.ipynb](link)
  - [ARS20GramOpt.pdf](link)

### Vergleichende Forschung
- [ARSvergleichMitAnderenMethoden.pdf](link)
- [ARSNaturalismusKonstruktivismusPostmodernismus.pdf](link)

---

## LLMs und soziologische Forschung
Große Sprachmodelle (LLMs) können die Algorithmisch Rekursive Sequenzanalyse ergänzen, insbesondere bei der Vorverarbeitung und Kategorisierung von Daten.

### Potenziale von LLMs
1. **Kategoriebildung:** Automatisierte Identifikation von Satzarten und Gesprächsakten.
2. **Grammatikinduktion:** Nutzung von Kategoriensymbolen zur Modellierung von Gesprächsstrukturen.
3. **Vergleich von Mustern:** Validierung durch Abgleich empirischer und künstlicher Daten.

### Vorteile des Ansatzes
Die Kombination einer empirisch optimierten, probabilistischen Grammatik mit der Flexibilität von LLMs stellt einen vielversprechenden hybriden Ansatz dar.

---

## Kontakt
Ich suche motivierte Nachfolgerinnen und Nachfolger, die die Weiterentwicklung der Algorithmisch Rekursiven Sequenzanalyse (ARS 2.0) vorantreiben möchten. Bei Interesse wenden Sie sich bitte an mich.

