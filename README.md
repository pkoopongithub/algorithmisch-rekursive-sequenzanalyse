Wenn man einen Hammer bauen will und eine Rakete fertigt, hat man auf hohem Niveau schlechte Arbeit gemacht. Und wenn man ein Lehrbuch der Volkswirtschaft schreiben will und einen Softwareagenten erschafft, der gerne mit Aktien handelt, hat man auf hohem Niveau schlechte Arbeit gemacht. Schlechte Arbeit hätte man auch gemacht, wenn man einen Chatbot erhält, weil man die Soziologie der  latenten generativen Strukturen  von Verhandlungen zwischen Käufer und Verkäufer algorithmisch beschreiben will. Solche Modelle benötigen weder postmoderne Tiefenhermeneutik oder postmoderne Dekonstruktion noch Large Language Modelle von Chatbots, sondern die syntaktische Analyse der regelbasierten Strukturen solcher sozialer Systeme.

If you want to build a hammer and a rocket manufactures you have done a bad job at a high level. And if you want to write an economics textbook and create a software agent that likes to trade stocks, you've done a bad job at a high level. You would have done bad work if you had a Chatbot obtained because one wants to algorithmically describe the sociology of the latent generative structures of negotiations between buyers and sellers. Such models require neither postmodern deep hermeneutics nor postmodern deconstruction, nor large language model chatbots, but the syntactic analysis of the rule-based structures of suchmore social systems.



Von Autonomen Fahren bis zu Generative Pre-Trained Transformern (GPT) und Large Language Modellen (LLM), die kaum über den Erklärungswert von Markow-Ketten hinausgehen, ist der Kampf zwischen Konnektionismus und Kognitivismus wieder entbrannt. Ethisch bedenkliche Opazität steht gegen ethisch vernünftige Transparenz. Und vieles erinnert an den ELIZA-Effekt, als menschliche Benutzer ein Eingaben spiegelndes Programm für einen aufmerksamen Berater hielten. Es gibt ein ethisches Grundproblem. GPT und LLM gehen nicht über ELIZA und Markow-Ketten hinaus. Nur sagt das niemand. Die Verantwortung liegt bei den Entwicklern. Das sagt auch niemand. Benötigt werden Dialogschnittstellen, deren Ergebnisqualität durch Systeme gesichert wird, die auf empirisch bewährten Dialoggrammatiken (Algorithmisch rekursive Sequenzanalyse) und Wissensdatenbanken der symbolischen Datenverarbeitung beruhen. Die Opazität des Konnektionismus (Generative Pre-Trained Transformer (GPT) und Large Language Modelle (LLM) ) sind das Problem, nicht die Lösung. Ethisch, unproblematisch und ergebnisorientiert sind allein symbolverarbeitende Systeme, die die Daten generieren. Generative Pre-Trained Transformer (GPT) und Large Language Modelle (LLM) dienen vernünftigerweise nur als Interface und nicht als Verkünder handlungsrelevanter Maximen.

From autonomous driving to Generative Pre-Trained Transformers (GPT) and Large Language Models (LLM), which barely go beyond the explanatory value of Markov chains, the battle between connectionism and cognitivism has flared up again. Ethically questionable opacity versus ethically sound transparency. And much is reminiscent of the ELIZA effect, when human users mistake a program that mirrors input for an attentive advisor. There is a basic ethical problem. GPT and LLM do not go beyond ELIZA and Markov chains. Only nobody says that. The responsibility lies with the developers. Nobody says that either. Dialog interfaces are required, the quality of the results of which is secured by systems based on empirically proven dialog grammars (algorithmically recursive sequence analysis) and knowledge databases of symbolic data processing. The opacity of connectionism (Generative Pre-Trained Transformer (GPT) and Large Language Models (LLM)) are the problem, not the solution. Only symbol-processing systems that generate the data are ethical, unproblematic and result-oriented. Generative Pre-Trained Transformers (GPT) and Large Language Models (LLM) only serve as an interface and not as a herald of action-relevant maxims.

De la conduite autonome aux Generative Pre-Trained Transformers (GPT) en passant par les Large Language Models (LLM), qui dépassent à peine la valeur explicative des chaînes de Markov, la bataille entre connexionnisme et cognitivisme a de nouveau éclaté. Opacité éthiquement discutable contre transparence éthiquement saine. Et beaucoup rappelle l'effet ELIZA, lorsque les utilisateurs humains confondent un programme qui reflète l'entrée avec un conseiller attentif. Il y a un problème éthique fondamental. GPT et LLM ne vont pas au-delà des chaînes ELIZA et Markov. Seulement personne ne dit ça. La responsabilité incombe aux développeurs. Personne ne le dit non plus. Des interfaces de dialogue sont nécessaires, dont la qualité des résultats est assurée par des systèmes basés sur des grammaires de dialogue éprouvées empiriquement (analyse de séquences récursives algorithmiques) et des bases de connaissances de traitement de données symboliques. L'opacité du connexionnisme (Generative Pre-Trained Transformer (GPT) et Large Language Models (LLM)) est le problème, pas la solution. Seuls les systèmes de traitement de symboles qui génèrent les données sont éthiques, sans problème et axés sur les résultats. Les transformateurs génératifs pré-formés (GPT) et les grands modèles de langage (LLM) ne servent que d'interface et non de héraut de maximes pertinentes pour l'action.

Desde la conducción autónoma hasta los Generative Pre-Trained Transformers (GPT) y los Large Language Models (LLM), que apenas superan el valor explicativo de las cadenas de Markov, la batalla entre conexionismo y cognitivismo ha vuelto a estallar. Opacidad éticamente cuestionable versus transparencia éticamente sólida. Y mucho recuerda al efecto ELIZA, cuando los usuarios humanos confunden un programa que refleja la entrada con un asesor atento. Hay un problema ético básico. GPT y LLM no van más allá de las cadenas ELIZA y Markov. Solo que nadie dice eso. La responsabilidad recae en los desarrolladores. Nadie dice eso tampoco. Se requieren interfaces de diálogo, cuya calidad de los resultados esté asegurada por sistemas basados ​​en gramáticas de diálogo empíricamente probadas (análisis de secuencia algorítmicamente recursivo) y bases de datos de conocimiento de procesamiento de datos simbólicos. La opacidad del conexionismo (Generative Pre-Trained Transformer (GPT) y Large Language Models (LLM)) son el problema, no la solución. Solo los sistemas de procesamiento de símbolos que generan los datos son éticos, no problemáticos y orientados a resultados. Los transformadores generativos preentrenados (GPT) y los modelos de lenguaje grande (LLM) solo sirven como una interfaz y no como un heraldo de máximas relevantes para la acción.

從自動駕駛到Generative Pre-Trained Transformers (GPT)，再到Large Language Models (LLM)，勉強超越了馬爾可夫鏈的解釋價值，聯結主義和認知主義的較量再次打響。 道德上有問題的不透明與道德上合理的透明度。 這讓人想起 ELIZA 效應，當人類用戶將反映輸入的程序誤認為是細心的顧問時。 存在一個基本的道德問題。 GPT 和 LLM 不超越 ELIZA 和馬爾可夫鏈。 只是沒有人這麼說。 責任在於開發商。 也沒有人這麼說。 需要對話界面，其結果的質量由基於經驗證明的對話語法（算法遞歸序列分析）和符號數據處理知識數據庫的系統保證。 連接主義（生成式預訓練轉換器 (GPT) 和大型語言模型 (LLM)）的不透明性是問題所在，而不是解決方案。 只有生成數據的符號處理系統才是道德的、沒有問題的和以結果為導向的。 生成式預訓練轉換器 (GPT) 和大型語言模型 (LLM) 僅用作接口，而不是動作相關格言的先驅。

От автономного вождения до генеративных предварительно обученных преобразователей (GPT) и больших языковых моделей (LLM), которые едва ли выходят за рамки объяснительной ценности цепей Маркова, битва между коннекционизмом и когнитивизмом снова разгорелась. Этически сомнительная непрозрачность в сравнении с этически обоснованной прозрачностью. И многое напоминает эффект ELIZA, когда люди-пользователи ошибочно принимают программу, отражающую входные данные, за внимательного консультанта. Существует основная этическая проблема. GPT и LLM не выходят за рамки ELIZA и цепей Маркова. Только никто так не говорит. Ответственность лежит на разработчиках. Так тоже никто не говорит. Требуются диалоговые интерфейсы, качество результатов которых обеспечивают системы, основанные на эмпирически проверенных диалоговых грамматиках (алгоритмически-рекурсивный анализ последовательностей) и базах знаний символьной обработки данных. Непрозрачность коннекционизма (Generative Pre-Trained Transformer (GPT) и Large Language Models (LLM)) — проблема, а не решение. Только системы обработки символов, которые генерируют данные, являются этичными, беспроблемными и ориентированными на результат. Генеративные предварительно обученные преобразователи (GPT) и большие языковые модели (LLM) служат только интерфейсом, а не глашатаем правил, относящихся к действию.


# algorithmisch-rekursive-sequenzanalyse
GERMAN

Verarbeitung natürlicher Sprache:
Korpuslinguistik:
Dialoggrammatik (K-System),
Grammatik-Induktion (Scheme),
Parsen (Pascal),
Grammatiktransduktion (Lisp).

Generative Pre-Trained Transformers (GPT) und Large Language Models (LLM) gehen kaum über den Erklärungswert von Markow-Ketten hinaus und müssen zudem mit der Wissensbasis empirisch ermittelter Dialoggrammatiken (Algorithmisch rekursive Sequenzanalyse) und agentenorientierter gewichteter Entscheidungstabellen für eine bessere Ergebnisqualität optimiert werden. Nur so werden Diaogschnittstellen glaubwürdiger als Markow-Generatoren und nur so werden Protokollsprachen für Agenten empirisch bewährte Dialogstrukturen abbilden.

Generative Pre-Trained Transformers (GPT) and Large Language Models (LLM) hardly go beyond the explanatory value of Markov chains and must also be optimized with the knowledge base of empirically determined dialog grammars (algorithmically recursive sequence analysis) and agent-oriented weighted decision tables for better quality results. Only in this way will dialog interfaces become more credible than Markov generators and only in this way will protocol languages for agents map empirically proven dialog structures.

Les transformateurs génératifs pré-entraînés (GPT) et les grands modèles de langage (LLM) ne dépassent guère la valeur explicative des chaînes de Markov et doivent également être optimisés avec la base de connaissances des grammaires de dialogue déterminées empiriquement (analyse de séquence récursive algorithmique) et la décision pondérée orientée agent. tableaux pour des résultats de meilleure qualité. Ce n'est qu'ainsi que les interfaces de dialogue deviendront plus crédibles que les générateurs de Markov et ce n'est qu'ainsi que les langages de protocole pour les agents cartographieront des structures de dialogue éprouvées empiriquement.

Los Transformadores Generativos (GPT) y los Modelos de Lenguaje Largo (LLM) pre-entrenados difícilmente van más allá del valor explicativo de las cadenas de Markov y también deben optimizarse con la base de conocimientos de las gramáticas de diálogo determinadas empíricamente (análisis de secuencias recursivas algorítmicas) y decisiones ponderadas orientadas a agentes . tablas para obtener mejores resultados. Solo entonces las interfaces de diálogo se vuelven más creíbles que los generadores de Markov y solo entonces los lenguajes de protocolo para los agentes mapean estructuras de diálogo probadas empíricamente.

預訓練的生成轉換器（GPT）和大型語言模型（LLM）很難超越馬爾可夫鏈的解釋價值，還必須利用經驗確定的對話語法（算法遞歸序列分析）和麵向主體的加權決策的知識庫進行優化. 表以獲得更好的結果。 只有這樣，對話界面才會變得比馬爾可夫生成器更可信，並且只有這樣，代理的協議語言才會映射經過經驗測試的對話結構。

Предварительно обученные генеративные преобразователи (GPT) и большие языковые модели (LLM) едва ли выходят за рамки объяснительной ценности цепей Маркова и также должны быть оптимизированы с помощью базы знаний эмпирически определенных диалоговых грамматик (алгоритмический рекурсивный анализ последовательности) и агентно-ориентированных взвешенных решений. . таблицы для лучшего результата. Только тогда диалоговые интерфейсы становятся более достоверными, чем марковские генераторы, и только тогда языки протоколов для агентов отображают эмпирически проверенные диалоговые структуры.




qualitative Sozialforschung: Textanalyse durch Sequenzanalyse, Grammatikinduktion, -transduktion, Parsen

Der Algorithmische Strukturalismus ist ein Versuch, dazu beizutragen, den genetischen Strukturalismus (ohne Auslassung und ohne Hinzufügung) in eine falsifizierbare Form zu übersetzten 
und empirisch bewährte Regelsysteme zu ermöglichen. Die Algorithmisch Rekursive Sequenzanalyse ist der erste systematische Versuch, 
einer naturalistischen und informatischen Ausformulierung des genetischen Strukturalismus als memetisches und evolutionäres Modell. 
Die Methodologie der Algorithmisch Rekursiven Sequenzanalyse ist der Algorithmische Strukturalismus. Der Algorithmische Strukturalismus
ist eine Formalisierung des genetischen Strukturalismus.Der genetische Strukturalismus (Oevermann) unterstellt einen intentionsfreien, 
apsychischen Möglichkeitsraum algorithmischer Regeln, die die Pragmatik wohlgeformter Ereignisketten textförmig strukturieren 
(Chomsky, McCarthy, Papert, Solomon, Lévi-Strauss, de Saussure, Austin, Searle). Der Algorithmische Strukturalismus ist der Versuch
den genetischen Strukturalismus falsifizierbar zu machen. Der Algorithmische Strukturalismus ist galileisch und an Habermas 
und Luhmann so wenig anschlußfähig, wie Galilei an Aristoteles. Natürlich kann man sich bemühen, an Luhmann oder Habermas 
anschlussfähig zu bleiben und Luhmann oder Habermas zu algorithmisieren. Algorithmisieren kann man alle Artefakte, 
zum Beispiel die Astrologie oder das Schachspiel. Und man kann normative Agenten verteilter künstlicher Intelligenz, 
Zelluläre Automaten, neuronale Netze und andere Modelle mit heuristischen Protokollsprachen und Regeln modellieren. 
Das ist zweifellos theoretisch wertvoll. So wird es keinen soziologischen Theoriefortschritt geben. Gesucht ist eine 
neue Soziologie, die die Replikation, Variation und Selektion sozialer Replikatoren, gespeichert in Artefakten und 
neuralen Mustern, modelliert. Diese neue Soziologie wird an Habermas oder Luhmann ebenso wenig anschlussfähig
sein wie Galilei an Aristoteles. Und ihre basalen Sätze werden so einfach sein wie die newtonschen Gesetze.
So wie Newton die Begriffe Bewegung, Beschleunigung, Kraft, Körper und Masse operational definierte, 
so wird diese Theorie die sozialen Replikatoren, ihre materiellen Substrate, ihre Replikation,
Variation und Selektion algorithmisch und operational definieren und sequenzanalytisch sichern. 
Soziale Strukturen sind sprachlich codiert und basieren auf einem digitalen Code. Gesucht sind 
syntaktische Strukturen einer Kultur codierenden Sprache. Aber dies wird keine philosophische Sprache sein,
sondern eine Sprache, die Gesellschaft codiert und erschafft. Diese Sprache codiert die Replikation, 
Variation und Selektion kultureller Replikatoren. Auf dieser Basis werden dann normative 
Agenten verteilter künstlicher Intelligenz, Zelluläre Automaten, neuronale Netze und andere 
Modelle andere als heuristische Protokollsprachen und Regelsysteme nutzen können, 
um die Evolution kultureller Replikatoren zu simulieren.

![Screenshot](./VKGinduktor.png)

ENGLISH

Natural Language Processing:
Corpus Linguistics:
Dialog Grammar (K-System),
Grammar Induction (Scheme),
Parsing (Pascal),
Grammar Transduction (Lisp.

Qualitative social research: text analysis through sequence analysis, grammar induction, grammar transduction, parsing

The genetic structuralism (Oevermann) assumes an intention-free, apsychic space of possibilities of algorithmic rules that structure the pragmatics of well-formed chains of events in text form (Chomsky, McCarthy, Papert, Solomon, Lévi-Strauss, de Saussure, Austin, Searle). Algorithmic structuralism is the attempt to make genetic structuralism falsifiable. Algorithmic structuralism is Galilean and based on Habermas and Luhmann as little compatible as Galileo with Aristotle. Of course you can try to contact Luhmann or Habermas to remain connected and to algorithmise Luhmann or Habermas. All artifacts can be algorithmized for example astrology or the game of chess. And normative agents of distributed artificial intelligence can be used, Model cellular automata, neural networks and other models with heuristic protocol languages ​​and rules. This is undoubtedly valuable in theory. So there will be no progress in sociological theory. We are looking for one new sociology involving the replication, variation and selection of social replicators, stored in artifacts and neural patterns, modeled. This new sociology is just as incompatible with Habermas or Luhmann be like Galileo to Aristotle. And their basic theorems will be as simple as Newton's laws. Just as Newton operationally defined the terms movement, acceleration, force, body and mass, so this theory becomes the social replicators, their material substrates, their replication, Define variation and selection algorithmically and operationally and secure them using sequence analysis. Social structures are linguistically coded and based on a digital code. Are wanted syntactic structures of a culture-coding language. But this won't be a philosophical language but a language that codes and creates society. This language encodes replication, Variation and selection of cultural replicators. On this basis, normative Distributed Artificial Intelligence Agents, Cellular Automata, Neural Networks, and others Models can use protocol languages ​​and rule systems other than heuristic, to simulate the evolution of cultural replicators.

Die Algorithmisch rekursive Sequenzanalyse ist das einzige mir bekannte objektiv hermeneutische Verfahren, das vollständig ohne esoterische Tiefenhermeneutik auskommt, algorithmisch, evolutionär und memetisch ausgerichtet ist und einen Grammatikinduktor (Scheme) , einen Parser (Pascal) und einen Grammatiktransduktur (Lisp) bietet. 

Das Düsseldorfer Schülerinventar ist das einzige mir bekannte quelloffene, valide, reliable und objektive Verfahren, dessen Quellen und Quellcodes überschaubar und nachvollziehbar nachprogrammierbar sind.

Ich freue mich über Erben, die die Verfahren aufgreifen, nachprogrammieren und/oder für Eigenentwicklungen davon inspirieren lassen.

The algorithmic recursive sequence analysis is the only objective hermeneutic method known to me that does not require any esoteric deep hermeneutics, is algorithmically, evolutionarily and memetically oriented and offers a grammar inductor (Scheme), a parser (Pascal) and a grammar transductor (Lisp).

The Düsseldorf student inventory is the only open-source, valid, reliable and objective method that I know of, whose sources and source codes are clear and understandable and can be reprogrammed.

I am happy about heirs who take up the process, reprogram it and/or let it inspire them for their own developments.
