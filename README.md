# Popper und die Grenzen großer Sprachmodelle (LLMs)

> **"Karl Popper betonte, dass Menschen das Leid der Evolution vermeiden können, indem sie falsche Theorien durch kritisches Denken und explizite Erklärungen erkennen und verwerfen. Dadurch bleibt der Fortschritt erhalten, ohne dass Menschen unnötig leiden müssen.**  
>
> **Große Sprachmodelle (LLMs) stehen diesem Prinzip entgegen. Sie entwickeln keine expliziten Theorien und erklären nichts, sondern operieren lediglich auf der Grundlage statistischer Muster. Ihre Opazität verhindert eine kritische Überprüfung ihrer Ergebnisse und macht sie unfähig, komplexe systemische Zusammenhänge oder soziale Missstände zu analysieren.**  
>
> **Ähnlich wie ein Schauspieler, der einen Chirurgen überzeugend imitiert, können sie Expertise simulieren, aber nicht die grundlegenden Probleme erklären – etwa soziale Ungleichheit oder Defizite im Gesundheitswesen.**  
>
> **Im Sinne von Poppers Philosophie sind jedoch explizite Erklärungen und Kritik unverzichtbar, um Fortschritt ohne Leid zu ermöglichen. LLMs, die diese Anforderungen nicht erfüllen, sind keine geeigneten Werkzeuge, um die Vision einer kritischen und aufgeklärten Gesellschaft zu verwirklichen."**

---

# Algorithmische Rekursive Sequenzanalyse (ARS 2.0)

## Projektbeschreibung
Dieses Projekt nutzt die **Algorithmisch Rekursive Sequenzanalyse (ARS 2.0)**, um die Dynamik von Gesprächen zu analysieren und zu modellieren. Dabei kommen probabilistische kontextfreie Grammatiken (PCFG) sowie Multiagentensysteme (MAS) zum Einsatz. Ziel ist die Simulation und Optimierung von Interaktionen, speziell im Bereich von Verkaufsgesprächen.

## Ziele
1. **Modellierung von Gesprächen:** Analyse und Simulation typischer Gesprächsabläufe.
2. **KI-Optimierung:** Entwicklung von Multiagentensystemen auf Basis induzierter Grammatiken.
3. **Wissenschaftliche Grundlagen:** Bereitstellung methodischer Ansätze für soziale Interaktionen, Verhandlungen und Beratung.

## Methoden
- **Grammatikinduktion:** Erstellung probabilistischer Grammatiken basierend auf Transkripten.
- **Simulation mit Multiagentensystemen:** Modellierung von Interaktionen.
- **Optimierung durch Datenanalyse:** Anpassung der Grammatik durch empirische Vergleiche.

---

## ARS 2024: Fortschrittliche Analyse und Implementierung

### Transkripte und Analysen
- **Grammatikinduktion:**
  - [ARS20AchtTranskripte.ipynb](./ARS20AchtTranskripte.ipynb)
  - [ars20achttranskripte.pdf](./ars20achttranskripte.pdf)

- **Einzeltranskriptanalyse:**
  - [ARS20BeispielEng.pdf](./ARS20BeispielEng.pdf)
  - [ARS20BeispielGer.pdf](./ARS20BeispielGer.pdf)

### Optimierung der Grammatik
- **Übergangswahrscheinlichkeiten:**
  - [ARS20GramOpt.ipynb](./ARS20GramOpt.ipynb)
  - [ARS20GramOpt.pdf](./ARS20GramOpt.pdf)

### Vergleichende Forschung
- [ARSvergleichMitAnderenMethoden.pdf](./ARSvergleichMitAnderenMethoden.pdf)
- [ARSNaturalismusKonstruktivismusPostmodernismus.pdf](./ARSNaturalismusKonstruktivismusPostmodernismus.pdf)

---

## LLMs und Soziologische Forschung
Große Sprachmodelle (LLMs) können die Algorithmisch Rekursive Sequenzanalyse ergänzen, insbesondere in der Vorverarbeitung und Kategorisierung.

### Potenziale von LLMs:
1. **Kategoriebildung:** Automatisierte Identifikation von Satzarten und Gesprächsakte.
2. **Grammatikinduktion:** Nutzung von Kategoriensymbolen zur Modellierung von Gesprächsstrukturen.
3. **Vergleich von Mustern:** Validierung durch Abgleich empirischer und künstlicher Daten.

### Vorteile des Ansatzes:
Eine empirisch optimierte, probabilistische Grammatik stellt einen Zwischenweg dar, der strukturierte Vorgaben mit der Flexibilität von LLMs kombiniert.

---

## Kontakt
Ich suche **Erben und Nachfolger**, die die Entwicklung der Algorithmisch Rekursiven Sequenzanalyse (ARS 2.0) fortsetzen möchten. Bei Interesse wenden Sie sich bitte an mich.
