Algorithmisch Rekursive Sequenzanalyse 2.0

Hier ist die verbesserte Version des Textes, gefolgt von der englischen Übersetzung:

---

Es wäre möglich, Methoden wie die objektive Hermeneutik (Oevermann) und die qualitative Inhaltsanalyse (Mayring) durch den Einsatz von Deep Learning und Large Language Models (LLMs) zu ersetzen, um Lesarten, Sinnstrukturen und Kategoriensysteme effizient zu erstellen und Interaktionen zu analysieren. Deep Learning und LLMs können große Mengen an Text- und Interaktionsdaten verarbeiten und komplexe Muster und Bedeutungsstrukturen autonom erkennen, was eine automatisierte und skalierbare Alternative zur manuellen, interpretativen Analyse der objektiven Hermeneutik darstellt. Durch das Training auf umfangreichen Datensätzen sind neuronale Netzwerke in der Lage, Sinnstrukturen und Kategorien zu identifizieren, die sonst mühsam manuell extrahiert werden müssten.

Die Entwicklung einer umfassenden Handlungsgrammatik, die Sinnstrukturen und Kategorien den strukturellen Regeln sozialer Interaktionen zuordnet, bleibt jedoch ein Bereich, der spezialisierte Werkzeuge und formale Programmiersprachen wie Lisp und Scheme erfordert. Die Algorithmisch Rekursive Sequenzanalyse bietet eine regelbasierte Methode zur Induktion von Grammatiken, die die Abfolge und Struktur von Interaktionen formalisiert. Lisp und Scheme eignen sich aufgrund ihrer Fähigkeit, rekursive und regelbasierte Prozesse zu modellieren, besonders gut für die algorithmische Analyse der Sinnstrukturen. In diesem Sinne bleibt die Handlungsgrammatik ein Aufgabenbereich für spezialisierte Werkzeuge und Methoden, die tiefgehende strukturelle Einsichten in soziale Sequenzen ermöglichen.

It would be possible to replace methods such as objective hermeneutics (Oevermann) and qualitative content analysis (Mayring) with Deep Learning and Large Language Models (LLMs) to efficiently create interpretations, meaning structures, and category systems, as well as to analyze interactions. Deep Learning and LLMs can process large amounts of text and interaction data, autonomously recognizing complex patterns and meaning structures, thus providing an automated and scalable alternative to the manual interpretative analysis of objective hermeneutics. By training on extensive datasets, neural networks can identify meaning structures and categories that would otherwise have to be painstakingly extracted manually.

However, developing a comprehensive action grammar that assigns meaning structures and categories to the structural rules of social interactions remains a field requiring specialized tools and formal programming languages such as Lisp and Scheme. Algorithmic Recursive Sequence Analysis offers a rule-based method for the induction of grammars, formalizing the sequence and structure of interactions. Lisp and Scheme are particularly well-suited for the algorithmic analysis of meaning structures due to their ability to model recursive and rule-based processes. In this sense, action grammar remains a specialized area for tools and methods that enable deeper structural insights into social sequences.

 Exposé zur Weiterentwicklung der Algorithmisch Rekursiven Sequenzanalyse (ARS)

 Projektziel
Ziel dieses Projektes ist es, die ursprünglich vor 35 Jahren entwickelte Algorithmisch Rekursive Sequenzanalyse (ARS) zu modernisieren und an die heutigen technologischen Gegebenheiten anzupassen. Dies umfasst die Integration fortschrittlicher Algorithmen der Künstlichen Intelligenz und des maschinellen Lernens in den bestehenden Rahmen, um die Analyse sozialer Handlungen und Interaktionen zu verfeinern und zu erweitern. Die Weiterentwicklung soll die Erzeugung und Auswertung von Terminalzeichenketten effizienter gestalten und neue Einsichten in latente soziale Strukturen ermöglichen.

 Vorgehensweise
1. Bestandsaufnahme und Analyse der bestehenden ARS: Eine detaillierte Analyse der ursprünglichen Implementierung wird durchgeführt, um Stärken und Schwächen zu identifizieren.

2. Integration moderner Technologien: Die bestehenden Komponenten (Parser, Induktor und Transduktor) werden aktualisiert und erweitert:
   - Parser: Implementierung eines neuen, KI-gestützten Parsers, der natürliche Sprache besser verarbeiten kann.
   - Induktor: Entwicklung eines maschinellen Lernmodells (z. B. mit TensorFlow oder PyTorch), das Muster in den Terminalzeichenketten erkennt und geeignete Grammatiken induziert.
   - Transduktor: Erweiterung des Transduktors durch den Einsatz von Neuronalen Netzwerken zur effektiven Generierung neuer Terminalzeichenketten.
   - Multiagentensystem: Verbesserung des bestehenden regelbasierten Multiagentensystems durch den Einsatz von KI-Technologien, um agentenbasiertes Verhalten zu simulieren und soziale Interaktionen dynamisch abzubilden.

3. Tests und Validierung: Durchführung von Testläufen mit realen Daten, um die Genauigkeit und Effizienz der neuen Systeme zu validieren.

4. Dokumentation und Dissemination: Zusammenstellung der Ergebnisse und Veröffentlichung in wissenschaftlichen Fachzeitschriften sowie auf Konferenzen.

 Extrapolierte Ergebnisse
Die Weiterentwicklung der ARS könnte zu signifikanten Fortschritten in der Analyse sozialer Interaktionen führen. Mögliche Ergebnisse umfassen:
- Verbesserte Mustererkennung: Durch den Einsatz modernster Algorithmen können latente Strukturen in sozialen Handlungen präziser identifiziert werden.
- Erweiterte Anwendungsmöglichkeiten: Die neue ARS kann auf verschiedene soziale Kontexte angewendet werden, einschließlich Marketing, politische Kommunikation und soziale Bewegungen.
- Simulation sozialer Systeme: Mit dem verbesserten Multiagentensystem könnten komplexe soziale Szenarien simuliert werden, die neue Erkenntnisse über soziale Dynamiken ermöglichen.

 Diskussion: Pro und Contra
Pro:
- Relevanz und Aktualität: Die moderne Gesellschaft benötigt präzisere Werkzeuge zur Analyse sozialer Interaktionen, insbesondere in Zeiten von sozialen Medien und digitaler Kommunikation.
- Technologischer Fortschritt: Die Integration von KI und maschinellem Lernen könnte die Effizienz und Aussagekraft der ARS erheblich steigern.
- Interdisziplinarität: Das Projekt fördert die Zusammenarbeit zwischen Informatik, Soziologie und Linguistik, was zu innovativen Ansätzen führen kann.

Contra:
- Komplexität der Implementierung: Die technischen Herausforderungen, die mit der Modernisierung und Integration neuer Technologien verbunden sind, könnten zu Verzögerungen und unerwarteten Problemen führen.
- Abhängigkeit von Daten: Die Genauigkeit der Ergebnisse hängt stark von der Qualität der verwendeten Daten ab. In vielen sozialen Kontexten können Daten unvollständig oder verzerrt sein.
- Ethik und Datenschutz: Die Erhebung und Analyse von sozialen Daten wirft ethische Fragen auf, die sorgfältig berücksichtigt werden müssen, um Datenschutzrichtlinien zu beachten.

 Fazit
Die Weiterentwicklung der Algorithmisch Rekursiven Sequenzanalyse stellt eine vielversprechende Möglichkeit dar, um die Analyse sozialer Interaktionen zu revolutionieren. Trotz der Herausforderungen, die mit der Implementierung neuer Technologien und der Berücksichtigung ethischer Aspekte verbunden sind, könnte dieses Projekt zu bedeutenden Erkenntnissen und Fortschritten in der Sozialwissenschaft führen.

---

 Repository-Inhalt
In diesem Repository finden Sie die bisherigen Programme für die ARS:
- Scheme: Induktor
- Lisp: Transduktor
- Pascal: Parser
- Python: Multiagentensystem (MAS)

Wir freuen uns auf Ihre Beiträge und Anregungen zur Weiterentwicklung dieses Projekts!
Algorithmic Recursive Sequence Analysis 2.0

 Exposé on the further development of Algorithmic Recursive Sequence Analysis (ARS)

 Project goal
The aim of this project is to modernize the algorithmic recursive sequence analysis (ARS), which was originally developed 35 years ago, and adapt it to today's technological circumstances. This includes integrating advanced artificial intelligence and machine learning algorithms into the existing framework to refine and expand the analysis of social actions and interactions. The further development is intended to make the generation and evaluation of terminal strings more efficient and enable new insights into latent social structures.

 Procedure
1. Inventory and Analysis of Existing ARS: A detailed analysis of the initial implementation is conducted to identify strengths and weaknesses.

2. Integration of modern technologies: The existing components (parser, inductor and transducer) are updated and expanded:
   - Parser: Implementation of a new, AI-powered parser that can better process natural language.
   - Inducer: Development of a machine learning model (e.g. with TensorFlow or PyTorch) that recognizes patterns in the terminal strings and induces appropriate grammars.
   - Transducer: Extension of the transducer through the use of neural networks to effectively generate new terminal strings.
   - Multi-agent system: Improving the existing rule-based multi-agent system by using AI technologies to simulate agent-based behavior and dynamically map social interactions.

3. Testing and Validation: Conducting test runs with real data to validate the accuracy and efficiency of the new systems.

4. Documentation and dissemination: Compilation of the results and publication in scientific journals and at conferences.

 Extrapolated results
Further development of ARS could lead to significant advances in the analysis of social interactions. Possible outcomes include:
- Improved pattern recognition: By using state-of-the-art algorithms, latent structures in social actions can be identified more precisely.
- Expanded applications: The new ARS can be applied to various social contexts, including marketing, political communication and social movements.
- Simulation of social systems: With the improved multi-agent system, complex social scenarios could be simulated, enabling new insights into social dynamics.

 Discussion: pros and cons
Pro:
- Relevance and timeliness: Modern society needs more precise tools for analyzing social interactions, especially in times of social media and digital communication.
- Technological advancements: The integration of AI and machine learning could significantly increase the efficiency and validity of ARS.
- Interdisciplinarity: The project promotes collaboration between computer science, sociology and linguistics, which can lead to innovative approaches.

Against:
- Complexity of implementation: The technical challenges associated with modernizing and integrating new technologies could lead to delays and unexpected problems.
- Dependence on data: The accuracy of the results depends heavily on the quality of the data used. In many social contexts, data can be incomplete or distorted.
- Ethics and privacy: The collection and analysis of social data raises ethical issues that must be carefully considered to comply with privacy policies.

 Conclusion
The further development of algorithmic recursive sequence analysis represents a promising opportunity to revolutionize the analysis of social interactions. Despite the challenges associated with implementing new technologies and considering ethical issues, this project could lead to significant insights and advances in social science.

---

 Repository content
In this repository you will find the previous programs for the ARS:
- Scheme: Inductor
- Lisp: Transduktor
- Pascal: Parser
- Python: Multiagentensystem (MAS)

We look forward to your contributions and suggestions for the further development of this project!





In den vergangenen vier Jahrzehnten hat sich die Forschung und Datenanalyse durch technologische Fortschritte tiefgreifend gewandelt. Die algorithmisch gestützte Rekonstruktion sozialer Interaktionen erfordert heute Ansätze, die große Datenmengen und die zunehmende Komplexität sozialer Phänomene berücksichtigen. Die *Algorithmisch Rekursive Sequenzanalyse (ARS)* ist eine innovative Softwarelösung, die Forschern ermöglicht, soziale Interaktionen strukturiert zu analysieren und latente Muster in Kommunikationsabläufen sichtbar zu machen. ARS nutzt Induktion, Parsing und Transduktion, um Handlungsgrammatiken zu generieren, die latente Sinnstrukturen abbilden – Strukturen, die in sozialen Interaktionen unbewusst und wiederkehrend reproduziert werden.

Vor 40 Jahren war ein solches Werkzeug aufgrund praktischer Einschränkungen nur eingeschränkt nutzbar. Die verfügbaren Datensätze beschränkten sich auf physische Tonband- oder Videoaufnahmen (Protokolle), die zunächst in schriftliche Form (Transkripte) übertragen werden mussten. Diese Transkripte wurden dann manuell von Auswertungsteams in einzelne Interakte zerlegt und mit symbolischen Kategorien versehen – ein zeitaufwändiger Prozess, der die Analyse und das Erkennen komplexer sozialer Strukturen erschwerte. Erst danach konnte mit der Modellierung der latenten Strukturen durch Handlungsgrammatiken begonnen werden, indem Terminalzeichenketten erstellt, aus diesen durch Induktion die Grammatik abgeleitet und anschließend die Strukturen durch Parsing und Transduktion empirisch validiert wurden.

Heute hingegen kann ARS dank moderner Algorithmen, leistungsfähiger Computerinfrastruktur und umfangreicher Datensätze sein volles Potenzial entfalten. Fortschritte in der Verarbeitung natürlicher Sprache, etwa durch große Sprachmodelle, ermöglichen eine Automatisierung der Transkription, Interaktanalyse und Kategorisierung. Dadurch lassen sich die latenten Handlungsstrukturen und Sinnmuster, die sozialen Interaktionen zugrunde liegen, gezielt offenlegen. ARS ist somit nicht nur ein Werkzeug für die qualitative Sozialforschung, sondern eröffnet als interdisziplinäres Forschungsinstrument neue Möglichkeiten des Verständnisses in den Sozialwissenschaften und darüber hinaus.



Over the past four decades, research and data analysis have been profoundly transformed by technological advancements. Algorithmic reconstruction of social interactions now demands approaches that address large datasets and the increasing complexity of social phenomena. The *Algorithmic Recursive Sequence Analysis (ARS)* is an innovative software solution that enables researchers to systematically analyze social interactions and uncover latent patterns in communication sequences. ARS employs induction, parsing, and transduction to generate action grammars that capture latent semantic structures—structures that are unconsciously and recurrently reproduced within social interactions.

Forty years ago, such a tool would have been limited by practical constraints. Available datasets were confined to physical audio or video recordings (protocols), which first had to be transcribed into written form (transcripts). These transcripts were then manually segmented by research teams into individual interaction acts and assigned symbolic categories—a time-intensive process that made the analysis and identification of complex social structures difficult. Only after this process could the modeling of latent structures through action grammars begin, involving the creation of terminal symbol sequences, the induction of grammar from these sequences, and the validation of structures via parsing and transduction against empirical data.

Today, however, ARS can fully leverage its potential thanks to modern algorithms, powerful computational infrastructure, and access to extensive datasets. Advances in natural language processing, including large language models, allow for automated transcription, interaction analysis, and categorization. This makes it possible to systematically reveal the latent action structures and meaning patterns that underlie social interactions. ARS thus serves not only as a tool for qualitative social research but also as an interdisciplinary research instrument, opening up new avenues for understanding within the social sciences and beyond. 

--- 

This version emphasizes the shifts from manual to automated processes, the application of action grammars, and the significance of ARS as an advanced tool for analyzing latent structures in social interactions.


Wenn das Ziel darin besteht, Verkaufsgespräche zu erklären – also die zugrunde liegenden Regeln, Ziele und Strukturen offen darzustellen –, dann ist ein generatives Modell wie ein LLM oft unzureichend. Ein LLM kann lediglich ähnliche Gespräche erzeugen oder imitieren, ohne die Absichten oder sozialen Mechanismen dahinter explizit zu machen.

 Wesentliche Punkte des Arguments

1. Nachahmung vs. Erklärung: LLMs sind darauf trainiert, Muster aus großen Textmengen zu lernen und Antworten zu generieren, die oberflächlich betrachtet einem Verkaufsgespräch ähneln können. Aber sie haben keine explizite Darstellung der Ziele, Strategien oder Regeln, die Verkaufsgespräche formen. Somit bleibt die Erklärung der zugrunde liegenden Strukturen unzureichend.
  
2. Erklärungsdefizit: Verkaufsgespräche folgen oft bestimmten Regeln und Zielen, wie zum Beispiel dem Aufbau von Vertrauen, der Ermittlung von Kundenbedürfnissen oder der Anwendung spezifischer Verhandlungstechniken. Ein LLM kann zwar solche Techniken reproduzieren, erklärt jedoch nicht, warum und wie diese Strategien funktionieren. Hierfür wäre ein analytischer Ansatz notwendig, der die Struktur und Dynamik solcher Gespräche explizit modelliert.

3. Beitrag von LLMs zu Verständniszwecken begrenzt: Da LLMs auf Wahrscheinlichkeitsverteilungen und Muster basieren, zeigen sie keine bewusste Zielgerichtetheit und keine kausalen Regeln, die Verkaufsgespräche leiten. Wenn das Ziel also darin besteht, die Funktionsweise dieser Gespräche zu verstehen und zu lehren, wäre ein LLM allein unzureichend – es braucht ergänzende Modelle oder Theorien, die die Handlungslogiken und Ziele explizit beschreiben.

 Ergänzende Ansätze zur Erklärung von Verkaufsgesprächen

- Regelbasierte Modelle: Durch die Verwendung von regelbasierten Systemen oder graphenbasierten Modellen könnten die Handlungslogiken, Ziele und Entscheidungsstrukturen von Verkaufsgesprächen explizit dargestellt werden. Diese Modelle könnten die spezifischen Verhaltensweisen und Reaktionen in einem Verkaufsgespräch verdeutlichen und die Verbindungen zwischen verschiedenen Gesprächszielen und -taktiken erklären.
  
- Agentenbasierte Modelle: Multiagentensysteme, die auf kausalen und regelbasierten Prinzipien basieren, könnten die Dynamik und das Ziel eines Verkaufsgesprächs explizit abbilden. Solche Systeme können zudem eine gewisse Zielgerichtetheit simulieren, die Verkaufsstrategien realistischer und transparenter macht.

- Dialoggrammatiken: Mit spezifischen Protokollen oder Dialoggrammatiken könnten die Abläufe und Regeln für Verkaufsgespräche detaillierter dargestellt und somit besser erklärt werden, als es durch ein generatives Modell möglich ist.




Das Argument ist schlüssig, da es darauf hinweist, dass die Fähigkeit, Verkaufsgespräche zu imitieren, nicht mit der Fähigkeit gleichzusetzen ist, diese Gespräche in ihren Regeln und Zielen zu erklären. Ein LLM mag Verkaufsgespräche simulieren können, aber ohne ein explizites Regelwerk und ohne Verständnis für die Ziele solcher Gespräche liefert es keine adäquate Erklärung.


Die Algorithmisch Rekursive Sequenzanalyse ist eine Methode zur Kausalinferenz mit Handlungsgrammatiken und Graphen. Im Gegensatz zu Poststrukturalisten, Postmodernisten, kritischen Posthumanisten, Konstruktivisten und Tiefenhermeneuten nimmt sie Karl Popper, Ulrich Oevermann, Chomsky, Pearl, Bayes, LISP, SCHEME, R und Python sehr ernst.

Algorithmic Recursive Sequence Analysis is a method for causal inference using action grammars and graphs. In contrast to poststructuralists, postmodernists, critical posthumanists, constructivists and depth hermeneutics, she takes Karl Popper, Ulrich Oevermann, Chomsky, Pearl, Bayes, LISP, SCHEME, R and Python very seriously.

If the goal is to explain sales conversations – that is, to openly present the underlying rules, goals and structures – then a generative model like an LLM is often inadequate. An LLM can only create or imitate similar conversations without making explicit the intentions or social mechanisms behind them.

 Key points of the argument

1. Imitation vs. Explanation: LLMs are trained to learn patterns from large amounts of text and generate responses that, on the surface, can resemble a sales pitch. But they have no explicit representation of the goals, strategies, or rules that shape sales conversations. The explanation of the underlying structures therefore remains inadequate.
  
2. Explanation deficit: Sales conversations often follow certain rules and goals, such as building trust, identifying customer needs or using specific negotiation techniques. While an LLM can reproduce such techniques, it does not explain why and how these strategies work. This would require an analytical approach that explicitly models the structure and dynamics of such conversations.

3. Contribution of LLMs to understanding purposes limited: Because LLMs are based on probability distributions and patterns, they do not demonstrate conscious targeting and causal rules guiding sales conversations. So if the goal is to understand and teach how these conversations work, an LLM alone would be inadequate - it needs complementary models or theories that explicitly describe the logic of action and goals.

 Complementary approaches to explaining sales conversations

- Rule-based models: By using rule-based systems or graph-based models, the action logic, goals and decision structures of sales discussions could be explicitly represented. These models could clarify the specific behaviors and reactions in a sales conversation and explain the connections between different conversation goals and tactics.
  
- Agent-based models: Multi-agent systems based on causal and rule-based principles could explicitly represent the dynamics and goal of a sales conversation. Such systems can also simulate a certain level of targeting that makes sales strategies more realistic and transparent.

- Dialogue grammars: With specific protocols or dialogue grammars, the processes and rules for sales discussions could be presented in more detail and thus better explained than is possible with a generative model.


Projektziele
Erklärung sozialer Interaktionen: Anstatt komplexe soziale Interaktionen und Verkaufsgespräche durch Black-Box-Modelle abzubilden, nutzen wir eine regelbasierte Sprache, die nachvollziehbare und interpretierbare Analysen ermöglicht.
Einsatz in Multiagentensystemen: Die entwickelte Sprache kann als Protokoll für Multiagentensysteme dienen und soll in Python implementiert werden. Der Einsatz solcher Protokollsprachen in Multiagentensystemen eröffnet neue Möglichkeiten, transparente und erklärbare Interaktionen zwischen Agenten zu ermöglichen.
Innovative Kombination von Methodologien: Der Ansatz verbindet Methoden der soziologischen Hermeneutik und Inhaltsanalyse mit einer formalisierten Sprachentwicklung. Hierdurch wird eine modellbasierte Grammatik induziert, die verschiedene Terminal- und Nicht-Terminal-Symbole umfasst, welche soziale Interaktionen als erklärbare Sequenzen abbilden.

Project Goals
Explaining Social Interactions: Instead of modeling complex social interactions and sales dialogues through black-box models, this project uses a rule-based language that enables understandable and interpretable analyses.
Use in Multi-Agent Systems: The developed language can serve as a protocol for multi-agent systems and will be implemented in Python. The use of such protocol languages in multi-agent systems opens up new possibilities for transparent and explainable interactions among agents.
Innovative Methodological Combination: This approach merges sociological hermeneutics and content analysis with formalized language development. A model-based grammar is induced, encompassing various terminal and non-terminal symbols that represent social interactions as explainable sequences.






Empirical social research is currently developing in three directions:
 
With the founding of the German Academy for Sociology, in Germany quantitative social research has regained importance and students have to learn the necessary basics again during their studies.
 
Qualitative social research continues on its way between deep hermeneutics and Oevermannian sequence analysis.
 
Multi-agent systems, neural nets, cellular automata, etc. continue to form the basis for the development of artificial social systems.
 
What is missing is qualitative social research that provides the empirically proven protocol languages for such artificial social systems, which serves to simulate empirically proven models (https://github.com/pkoopongithub). This is not possible with large language models, which hardly go beyond the explanatory value of Markov chains, but only with graph-based models that depict causal inference and rule-based action in an explanatory manner.

Die empirische Sozialforschung entwickelt sich derzeit in drei Richtungen:

Mit der Gründung der Deutschen Akademie für Soziologie hat in Deutschland die quantitative Sozialforschung wieder an Bedeutung gewonnen und die Studierenden müssen sich während des Studiums die notwendigen Grundlagen neu aneignen.
 
Die qualitative Sozialforschung bewegt sich weiter zwischen Tiefenhermeneutik und Oevermannscher Sequenzanalyse.
 
Multiagentensysteme, neuronale Netze, zellulare Automaten etc. bilden weiterhin die Grundlage für die Entwicklung künstlicher sozialer Systeme.
 
Was fehlt, ist eine qualitative Sozialforschung, die die empirisch erprobten Protokollsprachen für solche künstlichen Sozialsysteme bereitstellt, die dazu dient, empirisch erprobte Modelle zu simulieren (https://github.com/pkoopongithub). Das geht nicht mit Large Language Modellen, die kaum über den Erklärungswert von Markow-Ketten hinausgehen, sondern nur mit graphenbasierten Modellen, die kausale Inferenz und regelbasiertes Handeln erklärend abbilden.


Wenn man einen Hammer bauen will und eine Rakete fertigt, hat man auf hohem Niveau schlechte Arbeit gemacht. Und wenn man ein Lehrbuch der Volkswirtschaft schreiben will und einen Softwareagenten erschafft, der gerne mit Aktien handelt, hat man auf hohem Niveau schlechte Arbeit gemacht. Schlechte Arbeit hätte man auch gemacht, wenn man einen Chatbot erhält, weil man die Soziologie der  latenten generativen Strukturen  von Verhandlungen zwischen Käufer und Verkäufer algorithmisch beschreiben will. Solche Modelle benötigen weder postmoderne Tiefenhermeneutik oder postmoderne Dekonstruktion noch Large Language Modelle von Chatbots, sondern die syntaktische Analyse der regelbasierten Strukturen solcher sozialer Systeme.

If you want to build a hammer and a rocket manufactures you have done a bad job at a high level. And if you want to write an economics textbook and create a software agent that likes to trade stocks, you've done a bad job at a high level. You would have done bad work if you had a Chatbot obtained because one wants to algorithmically describe the sociology of the latent generative structures of negotiations between buyers and sellers. Such models require neither postmodern deep hermeneutics nor postmodern deconstruction, nor large language model chatbots, but the syntactic analysis of the rule-based structures of suchmore social systems.


Posthumanismus und Transhumanismus müssen die Opake KI entweder parasitieren oder ihre Symbionten sein. Denn sie leben entweder von ihrer Opazität oder die Liebe zur Opazität ist ihre gemeinsame Wurzel. In dem Fall aber haben sie alle Drei Karl Popper durch Harry Potter ersetzt und betreiben Magie. Denn bei ausreichender Speicherkapazität und genügend Rechengeschwindigkeit wirkt jeder reine Markov-Generator intelligent und Markov-Generatoren, die mit hoher Rechengeschwindigkeit über einer ausreichend großen Speicherkapazität arbeiten, sind der Cargo-Kult des Verstandes.

Posthumanism and transhumanism must either parasitize the Opaque AI or be its symbiote. Because they live either from their opacity or the love for opacity is their common root. In this case, however, they have all three replaced Karl Popper with Harry Potter and practice magic. Because with sufficient storage capacity and sufficient computing speed, everyone looks pureMarkov Generator intelligent and Markov generators with high computing speed over a sufficient huge storage capacity work are the cargo cult of the mind.




Von Autonomen Fahren bis zu Generative Pre-Trained Transformern (GPT) und Large Language Modellen (LLM), die kaum über den Erklärungswert von Markow-Ketten hinausgehen, ist der Kampf zwischen Konnektionismus und Kognitivismus wieder entbrannt. Ethisch bedenkliche Opazität steht gegen ethisch vernünftige Transparenz. Und vieles erinnert an den ELIZA-Effekt, als menschliche Benutzer ein Eingaben spiegelndes Programm für einen aufmerksamen Berater hielten. Es gibt ein ethisches Grundproblem. GPT und LLM gehen nicht über ELIZA und Markow-Ketten hinaus. Nur sagt das niemand. Die Verantwortung liegt bei den Entwicklern. Das sagt auch niemand. Benötigt werden Dialogschnittstellen, deren Ergebnisqualität durch Systeme gesichert wird, die auf empirisch bewährten Dialoggrammatiken (Algorithmisch rekursive Sequenzanalyse) und Wissensdatenbanken der symbolischen Datenverarbeitung beruhen. Die Opazität des Konnektionismus (Generative Pre-Trained Transformer (GPT) und Large Language Modelle (LLM) ) sind das Problem, nicht die Lösung. Ethisch, unproblematisch und ergebnisorientiert sind allein symbolverarbeitende Systeme, die die Daten generieren. Generative Pre-Trained Transformer (GPT) und Large Language Modelle (LLM) dienen vernünftigerweise nur als Interface und nicht als Verkünder handlungsrelevanter Maximen.

From autonomous driving to Generative Pre-Trained Transformers (GPT) and Large Language Models (LLM), which barely go beyond the explanatory value of Markov chains, the battle between connectionism and cognitivism has flared up again. Ethically questionable opacity versus ethically sound transparency. And much is reminiscent of the ELIZA effect, when human users mistake a program that mirrors input for an attentive advisor. There is a basic ethical problem. GPT and LLM do not go beyond ELIZA and Markov chains. Only nobody says that. The responsibility lies with the developers. Nobody says that either. Dialog interfaces are required, the quality of the results of which is secured by systems based on empirically proven dialog grammars (algorithmically recursive sequence analysis) and knowledge databases of symbolic data processing. The opacity of connectionism (Generative Pre-Trained Transformer (GPT) and Large Language Models (LLM)) are the problem, not the solution. Only symbol-processing systems that generate the data are ethical, unproblematic and result-oriented. Generative Pre-Trained Transformers (GPT) and Large Language Models (LLM) only serve as an interface and not as a herald of action-relevant maxims.

De la conduite autonome aux Generative Pre-Trained Transformers (GPT) en passant par les Large Language Models (LLM), qui dépassent à peine la valeur explicative des chaînes de Markov, la bataille entre connexionnisme et cognitivisme a de nouveau éclaté. Opacité éthiquement discutable contre transparence éthiquement saine. Et beaucoup rappelle l'effet ELIZA, lorsque les utilisateurs humains confondent un programme qui reflète l'entrée avec un conseiller attentif. Il y a un problème éthique fondamental. GPT et LLM ne vont pas au-delà des chaînes ELIZA et Markov. Seulement personne ne dit ça. La responsabilité incombe aux développeurs. Personne ne le dit non plus. Des interfaces de dialogue sont nécessaires, dont la qualité des résultats est assurée par des systèmes basés sur des grammaires de dialogue éprouvées empiriquement (analyse de séquences récursives algorithmiques) et des bases de connaissances de traitement de données symboliques. L'opacité du connexionnisme (Generative Pre-Trained Transformer (GPT) et Large Language Models (LLM)) est le problème, pas la solution. Seuls les systèmes de traitement de symboles qui génèrent les données sont éthiques, sans problème et axés sur les résultats. Les transformateurs génératifs pré-formés (GPT) et les grands modèles de langage (LLM) ne servent que d'interface et non de héraut de maximes pertinentes pour l'action.

Desde la conducción autónoma hasta los Generative Pre-Trained Transformers (GPT) y los Large Language Models (LLM), que apenas superan el valor explicativo de las cadenas de Markov, la batalla entre conexionismo y cognitivismo ha vuelto a estallar. Opacidad éticamente cuestionable versus transparencia éticamente sólida. Y mucho recuerda al efecto ELIZA, cuando los usuarios humanos confunden un programa que refleja la entrada con un asesor atento. Hay un problema ético básico. GPT y LLM no van más allá de las cadenas ELIZA y Markov. Solo que nadie dice eso. La responsabilidad recae en los desarrolladores. Nadie dice eso tampoco. Se requieren interfaces de diálogo, cuya calidad de los resultados esté asegurada por sistemas basados ​​en gramáticas de diálogo empíricamente probadas (análisis de secuencia algorítmicamente recursivo) y bases de datos de conocimiento de procesamiento de datos simbólicos. La opacidad del conexionismo (Generative Pre-Trained Transformer (GPT) y Large Language Models (LLM)) son el problema, no la solución. Solo los sistemas de procesamiento de símbolos que generan los datos son éticos, no problemáticos y orientados a resultados. Los transformadores generativos preentrenados (GPT) y los modelos de lenguaje grande (LLM) solo sirven como una interfaz y no como un heraldo de máximas relevantes para la acción.

從自動駕駛到Generative Pre-Trained Transformers (GPT)，再到Large Language Models (LLM)，勉強超越了馬爾可夫鏈的解釋價值，聯結主義和認知主義的較量再次打響。 道德上有問題的不透明與道德上合理的透明度。 這讓人想起 ELIZA 效應，當人類用戶將反映輸入的程序誤認為是細心的顧問時。 存在一個基本的道德問題。 GPT 和 LLM 不超越 ELIZA 和馬爾可夫鏈。 只是沒有人這麼說。 責任在於開發商。 也沒有人這麼說。 需要對話界面，其結果的質量由基於經驗證明的對話語法（算法遞歸序列分析）和符號數據處理知識數據庫的系統保證。 連接主義（生成式預訓練轉換器 (GPT) 和大型語言模型 (LLM)）的不透明性是問題所在，而不是解決方案。 只有生成數據的符號處理系統才是道德的、沒有問題的和以結果為導向的。 生成式預訓練轉換器 (GPT) 和大型語言模型 (LLM) 僅用作接口，而不是動作相關格言的先驅。

От автономного вождения до генеративных предварительно обученных преобразователей (GPT) и больших языковых моделей (LLM), которые едва ли выходят за рамки объяснительной ценности цепей Маркова, битва между коннекционизмом и когнитивизмом снова разгорелась. Этически сомнительная непрозрачность в сравнении с этически обоснованной прозрачностью. И многое напоминает эффект ELIZA, когда люди-пользователи ошибочно принимают программу, отражающую входные данные, за внимательного консультанта. Существует основная этическая проблема. GPT и LLM не выходят за рамки ELIZA и цепей Маркова. Только никто так не говорит. Ответственность лежит на разработчиках. Так тоже никто не говорит. Требуются диалоговые интерфейсы, качество результатов которых обеспечивают системы, основанные на эмпирически проверенных диалоговых грамматиках (алгоритмически-рекурсивный анализ последовательностей) и базах знаний символьной обработки данных. Непрозрачность коннекционизма (Generative Pre-Trained Transformer (GPT) и Large Language Models (LLM)) — проблема, а не решение. Только системы обработки символов, которые генерируют данные, являются этичными, беспроблемными и ориентированными на результат. Генеративные предварительно обученные преобразователи (GPT) и большие языковые модели (LLM) служат только интерфейсом, а не глашатаем правил, относящихся к действию.


# algorithmisch-rekursive-sequenzanalyse
GERMAN

Verarbeitung natürlicher Sprache:
Korpuslinguistik:
Handlungsgrammatik, Dialoggrammatik (K-System),
Grammatik-Induktion (Scheme),
Parsen (Pascal),
Grammatiktransduktion (Lisp).

Generative Pre-Trained Transformers (GPT) und Large Language Models (LLM) gehen kaum über den Erklärungswert von Markow-Ketten hinaus und müssen zudem mit der Wissensbasis empirisch ermittelter Dialoggrammatiken (Algorithmisch rekursive Sequenzanalyse) und agentenorientierter gewichteter Entscheidungstabellen für eine bessere Ergebnisqualität optimiert werden. Nur so werden Diaogschnittstellen glaubwürdiger als Markow-Generatoren und nur so werden Protokollsprachen für Agenten empirisch bewährte Dialogstrukturen abbilden.

Generative Pre-Trained Transformers (GPT) and Large Language Models (LLM) hardly go beyond the explanatory value of Markov chains and must also be optimized with the knowledge base of empirically determined dialog grammars (algorithmically recursive sequence analysis) and agent-oriented weighted decision tables for better quality results. Only in this way will dialog interfaces become more credible than Markov generators and only in this way will protocol languages for agents map empirically proven dialog structures.

Les transformateurs génératifs pré-entraînés (GPT) et les grands modèles de langage (LLM) ne dépassent guère la valeur explicative des chaînes de Markov et doivent également être optimisés avec la base de connaissances des grammaires de dialogue déterminées empiriquement (analyse de séquence récursive algorithmique) et la décision pondérée orientée agent. tableaux pour des résultats de meilleure qualité. Ce n'est qu'ainsi que les interfaces de dialogue deviendront plus crédibles que les générateurs de Markov et ce n'est qu'ainsi que les langages de protocole pour les agents cartographieront des structures de dialogue éprouvées empiriquement.

Los Transformadores Generativos (GPT) y los Modelos de Lenguaje Largo (LLM) pre-entrenados difícilmente van más allá del valor explicativo de las cadenas de Markov y también deben optimizarse con la base de conocimientos de las gramáticas de diálogo determinadas empíricamente (análisis de secuencias recursivas algorítmicas) y decisiones ponderadas orientadas a agentes . tablas para obtener mejores resultados. Solo entonces las interfaces de diálogo se vuelven más creíbles que los generadores de Markov y solo entonces los lenguajes de protocolo para los agentes mapean estructuras de diálogo probadas empíricamente.

預訓練的生成轉換器（GPT）和大型語言模型（LLM）很難超越馬爾可夫鏈的解釋價值，還必須利用經驗確定的對話語法（算法遞歸序列分析）和麵向主體的加權決策的知識庫進行優化. 表以獲得更好的結果。 只有這樣，對話界面才會變得比馬爾可夫生成器更可信，並且只有這樣，代理的協議語言才會映射經過經驗測試的對話結構。

Предварительно обученные генеративные преобразователи (GPT) и большие языковые модели (LLM) едва ли выходят за рамки объяснительной ценности цепей Маркова и также должны быть оптимизированы с помощью базы знаний эмпирически определенных диалоговых грамматик (алгоритмический рекурсивный анализ последовательности) и агентно-ориентированных взвешенных решений. . таблицы для лучшего результата. Только тогда диалоговые интерфейсы становятся более достоверными, чем марковские генераторы, и только тогда языки протоколов для агентов отображают эмпирически проверенные диалоговые структуры.




qualitative Sozialforschung: Textanalyse durch Sequenzanalyse, Grammatikinduktion, -transduktion, Parsen

Der Algorithmische Strukturalismus ist ein Versuch, dazu beizutragen, den genetischen Strukturalismus (ohne Auslassung und ohne Hinzufügung) in eine falsifizierbare Form zu übersetzten 
und empirisch bewährte Regelsysteme zu ermöglichen. Die Algorithmisch Rekursive Sequenzanalyse ist der erste systematische Versuch, 
einer naturalistischen und informatischen Ausformulierung des genetischen Strukturalismus als memetisches und evolutionäres Modell. 
Die Methodologie der Algorithmisch Rekursiven Sequenzanalyse ist der Algorithmische Strukturalismus. Der Algorithmische Strukturalismus
ist eine Formalisierung des genetischen Strukturalismus.Der genetische Strukturalismus (Oevermann) unterstellt einen intentionsfreien, 
apsychischen Möglichkeitsraum algorithmischer Regeln, die die Pragmatik wohlgeformter Ereignisketten textförmig strukturieren 
(Chomsky, McCarthy, Papert, Solomon, Lévi-Strauss, de Saussure, Austin, Searle). Der Algorithmische Strukturalismus ist der Versuch
den genetischen Strukturalismus falsifizierbar zu machen. Der Algorithmische Strukturalismus ist galileisch und an Habermas 
und Luhmann so wenig anschlußfähig, wie Galilei an Aristoteles. Natürlich kann man sich bemühen, an Luhmann oder Habermas 
anschlussfähig zu bleiben und Luhmann oder Habermas zu algorithmisieren. Algorithmisieren kann man alle Artefakte, 
zum Beispiel die Astrologie oder das Schachspiel. Und man kann normative Agenten verteilter künstlicher Intelligenz, 
Zelluläre Automaten, neuronale Netze und andere Modelle mit heuristischen Protokollsprachen und Regeln modellieren. 
Das ist zweifellos theoretisch wertvoll. So wird es keinen soziologischen Theoriefortschritt geben. Gesucht ist eine 
neue Soziologie, die die Replikation, Variation und Selektion sozialer Replikatoren, gespeichert in Artefakten und 
neuralen Mustern, modelliert. Diese neue Soziologie wird an Habermas oder Luhmann ebenso wenig anschlussfähig
sein wie Galilei an Aristoteles. Und ihre basalen Sätze werden so einfach sein wie die newtonschen Gesetze.
So wie Newton die Begriffe Bewegung, Beschleunigung, Kraft, Körper und Masse operational definierte, 
so wird diese Theorie die sozialen Replikatoren, ihre materiellen Substrate, ihre Replikation,
Variation und Selektion algorithmisch und operational definieren und sequenzanalytisch sichern. 
Soziale Strukturen sind sprachlich codiert und basieren auf einem digitalen Code. Gesucht sind 
syntaktische Strukturen einer Kultur codierenden Sprache. Aber dies wird keine philosophische Sprache sein,
sondern eine Sprache, die Gesellschaft codiert und erschafft. Diese Sprache codiert die Replikation, 
Variation und Selektion kultureller Replikatoren. Auf dieser Basis werden dann normative 
Agenten verteilter künstlicher Intelligenz, Zelluläre Automaten, neuronale Netze und andere 
Modelle andere als heuristische Protokollsprachen und Regelsysteme nutzen können, 
um die Evolution kultureller Replikatoren zu simulieren.

![Screenshot](./VKGinduktor.png)

ENGLISH

Natural Language Processing:
Corpus Linguistics:
Action Grammar, Dialog Grammar (K-System),
Grammar Induction (Scheme),
Parsing (Pascal),
Grammar Transduction (Lisp.

Qualitative social research: text analysis through sequence analysis, grammar induction, grammar transduction, parsing

The genetic structuralism (Oevermann) assumes an intention-free, apsychic space of possibilities of algorithmic rules that structure the pragmatics of well-formed chains of events in text form (Chomsky, McCarthy, Papert, Solomon, Lévi-Strauss, de Saussure, Austin, Searle). Algorithmic structuralism is the attempt to make genetic structuralism falsifiable. Algorithmic structuralism is Galilean and based on Habermas and Luhmann as little compatible as Galileo with Aristotle. Of course you can try to contact Luhmann or Habermas to remain connected and to algorithmise Luhmann or Habermas. All artifacts can be algorithmized for example astrology or the game of chess. And normative agents of distributed artificial intelligence can be used, Model cellular automata, neural networks and other models with heuristic protocol languages ​​and rules. This is undoubtedly valuable in theory. So there will be no progress in sociological theory. We are looking for one new sociology involving the replication, variation and selection of social replicators, stored in artifacts and neural patterns, modeled. This new sociology is just as incompatible with Habermas or Luhmann be like Galileo to Aristotle. And their basic theorems will be as simple as Newton's laws. Just as Newton operationally defined the terms movement, acceleration, force, body and mass, so this theory becomes the social replicators, their material substrates, their replication, Define variation and selection algorithmically and operationally and secure them using sequence analysis. Social structures are linguistically coded and based on a digital code. Are wanted syntactic structures of a culture-coding language. But this won't be a philosophical language but a language that codes and creates society. This language encodes replication, Variation and selection of cultural replicators. On this basis, normative Distributed Artificial Intelligence Agents, Cellular Automata, Neural Networks, and others Models can use protocol languages ​​and rule systems other than heuristic, to simulate the evolution of cultural replicators.

Die Algorithmisch rekursive Sequenzanalyse ist das einzige mir bekannte objektiv hermeneutische Verfahren, das vollständig ohne esoterische Tiefenhermeneutik auskommt, algorithmisch, evolutionär und memetisch ausgerichtet ist und einen Grammatikinduktor (Scheme) , einen Parser (Pascal) und einen Grammatiktransduktur (Lisp) bietet. 

Das Düsseldorfer Schülerinventar ist das einzige mir bekannte quelloffene, valide, reliable und objektive Verfahren, dessen Quellen und Quellcodes überschaubar und nachvollziehbar nachprogrammierbar sind.

Ich freue mich über Erben, die die Verfahren aufgreifen, nachprogrammieren und/oder für Eigenentwicklungen davon inspirieren lassen.

The algorithmic recursive sequence analysis is the only objective hermeneutic method known to me that does not require any esoteric deep hermeneutics, is algorithmically, evolutionarily and memetically oriented and offers a grammar inductor (Scheme), a parser (Pascal) and a grammar transductor (Lisp).

The Düsseldorf student inventory is the only open-source, valid, reliable and objective method that I know of, whose sources and source codes are clear and understandable and can be reprogrammed.

I am happy about heirs who take up the process, reprogram it and/or let it inspire them for their own developments.
